[{"title":"对ffmpeg中时间基与时间戳的理解","url":"/2024/12/05/对ffmpeg中时间基与时间戳的理解/","content":"\n### 时间基与时间戳的基本概念\n在 FFmpeg 中，时间基(time_base)是时间戳(timestamp)的单位，时间戳值乘以时间基，可以得到实际的时刻值(以秒等为单位)。\n\n### pts和dts\n这里我将pts和dts简单的理解为`pts是播放时间`，`dts是解码时间`\n视频帧的解码时间和播放时间可能不同，尤其是当视频帧包含B帧时。对于I帧，解码时间和播放时间相同。而B帧和P帧的dts和pts就会不一样。\n音频帧的解码时间和播放时间绝大多数的情况下是相同的，因为音频帧按顺序解码并播放。\n\n### 视频流和音频流pts和dts的设置\n#### 视频流\n视频按帧播放，所以解码后的原始视频帧时间基为 1/帧率。  \n例如，对于高清视频，时间基的 `num` 和 `den` 为 1 和 90000，时间基就是 1/90000。这样计算视频的时间戳就是 `1 / 25 * 90000`。  \n即pts就是`1 / 25 * 90000`，而dts我发现不设置也可以(但具体原因我也不知道，有知道的还请一定指点一二，拜托了`(ಥ _ ಥ)`)\n其中，`25` 是视频的帧率（frames per second，fps），即每秒钟的帧数。  \n通过将时间戳乘以时间基，可以得到实际的播放时间。换算成时间基的目的，主要是为了统一不视频流的时间单位，就像统一国际单位一样，不同帧率的视频时间戳都有统一的单位，这样的换算也能进一步提高精度。\n\n#### 音频流\n音频按采样点播放，所以解码后的原始音频帧时间基为 1/采样率。  \n这样音频的时间戳设置就是采样数，时间基就是采样率的倒数。即，采样率越高，每个采样点的时间基就越小。\n\n### 重点\n理解这些最需要记住的一点是：**时间基乘以时间戳得到的是实际时间**。","tags":["FFmpeg"],"categories":["音视频"]},{"title":"解决git操作push失败的问题","url":"/2024/12/04/解决git操作push失败的问题/","content":"\n从网上找到了一个教程，解决了一个烦人的问题\n\n### 设置代理\n```bash\ngit config --global http.proxy http://127.0.0.1:7890  \ngit config --global https.proxy http://127.0.0.1:7890\n```\n\n### 取消和查看代理\n\n#### 取消代理\n```bash\ngit config --global --unset http.proxy  \ngit config --global --unset https.proxy\n```\n\n#### 查看代理\n```bash\ngit config --global --get http.proxy  \ngit config --global --get https.proxy  \ngit config --list\n```\n\n原文链接：[https://blog.csdn.net/Naylor_5/article/details/135648311](https://blog.csdn.net/Naylor_5/article/details/135648311)","tags":["git","解决"],"categories":["杂项"]},{"title":"利用rtmp对本地flv文件进行推流","url":"/2024/12/03/利用rtmp对本地flv文件进行推流/","content":"\n### 实现了从一个 FLV 文件读取音视频数据，并通过 RTMP 协议进行推流。核心步骤包括：\n\n#### **FLV 文件头解析 (openfile)**  \n   - **功能**: 打开并读取 FLV 文件，跳过文件头（9 字节）。  \n   - **步骤**:\n     - 打开指定的 FLV 文件。\n     - 检查文件是否成功打开。如果打开失败，则返回 `nullptr`。\n     - 跳过文件头的 9 字节，定位到数据部分。\n\n```cpp\nstatic QFile *openfile(char *flv_name) {\n    QFile *file = new QFile(flv_name);\n    if(!file->open(QFile::ReadOnly)){\n        qDebug() << \"文件打开失败!\";\n        return nullptr;\n    }\n    file->seek(9); //跳过 9字节 header\n    return file;\n}\n```\n\n#### **RTMP 连接 (connect_rtmp_server)**  \n   - **功能**: 初始化 RTMP 连接到 RTMP 服务器。  \n   - **步骤**:\n     - 检查 RTMP 地址是否为空。\n     - 创建并初始化 RTMP 对象。\n     - 设置 RTMP 服务器地址和连接超时时间。\n     - 进行连接，并设置为推流模式（调用 `RTMP_EnableWrite`）。\n     - 创建并连接流。\n\n```cpp\nstatic RTMP *connect_rtmp_server(char *rtmpaddr) {\n    if(rtmpaddr == NULL){\n        qDebug() << \"连接的RTMP地址为空!\";\n        return NULL;\n    }\n    RTMP *rtmp = nullptr;\n    rtmp = RTMP_Alloc();\n    RTMP_Init(rtmp);\n    if(!rtmp){\n        qDebug() << \"Failed to alloc RTMP object!\";\n        goto __ERROR;\n    }\n\n    RTMP_SetupURL(rtmp, rtmpaddr);\n    rtmp->Link.timeout = 10;\n\n    if(!RTMP_Connect(rtmp, NULL)){\n        qDebug() << \"Failed to connect RTMP Server!\";\n        goto __ERROR;\n    }\n\n    RTMP_EnableWrite(rtmp);\n    RTMP_ConnectStream(rtmp, 0);\n\n    return rtmp;\n__ERROR:\n    if(rtmp){\n        RTMP_Close(rtmp);\n        RTMP_Free(rtmp);\n    }\n    return NULL;\n}\n```\n\n#### **RTMP 数据包分配 (alloc_packet)**  \n   - **功能**: 为 RTMP 数据包分配内存并初始化。  \n   - **步骤**:\n     - 分配 `RTMPPacket` 内存空间。\n     - 分配 64KB 内存空间用于数据包。\n     - 重置数据包并设置初始值。\n\n```cpp\nstatic RTMPPacket *alloc_packet() {\n    RTMPPacket *packet = NULL;\n    packet = (RTMPPacket *)malloc(sizeof(RTMPPacket));\n    if(!packet){\n        qDebug() << \"Failed to alloc RTMPPacket!\";\n        return NULL;\n    }\n\n    RTMPPacket_Alloc(packet, 64 * 1024);\n    RTMPPacket_Reset(packet);\n\n    packet->m_hasAbsTimestamp = 0;\n    packet->m_nChannel = 0x4;\n\n    return packet;\n}\n```\n\n#### **读取 FLV 数据并填充 RTMP 数据包 (read_data)**  \n   - **功能**: 逐个读取 FLV 文件中的数据块并填充 RTMP 数据包。  \n   - **步骤**:\n     - 跳过前 4 字节的 `pre-tag size`。\n     - 读取 tag type、tag data size、时间戳和流 ID。\n     - 读取实际的 tag 数据体，并将其填充到 `RTMPPacket` 中。\n\n```cpp\nstatic int read_data(QFile *file, RTMPPacket **packet) {\n    if (!file || !packet) {\n        qDebug() << \"Error: Invalid arguments.\";\n        return 0;\n    }\n\n    int ret = 0;\n    QByteArray tt, tag_data_size, ts, streamid;\n\n    file->read(4);  // 跳过 pre-tag size\n    tt = file->read(1);  // 读取 tag type\n    tag_data_size = file->read(3);  // 读取 tag data size\n\n    unsigned int tagDataSize = ((unsigned char)tag_data_size[0] << 16)\n                               | ((unsigned char)tag_data_size[1] << 8)\n                               | (unsigned char)tag_data_size[2];\n\n    if (file->bytesAvailable() < tagDataSize) {\n        qDebug() << \"Error: Insufficient data for tag body.\";\n        return 0;\n    }\n\n    ts = file->read(4);  // 读取时间戳\n    unsigned int timestamp = ((unsigned char)ts[0] << 16)\n                             | ((unsigned char)ts[1] << 8)\n                             | ((unsigned char)ts[2]);\n\n    streamid = file->read(3);  // 读取流 ID\n    QByteArray bodyData = file->read(tagDataSize);  // 读取 tag body\n\n    (*packet)->m_packetType = static_cast<unsigned char>(tt[0]);\n    std::memcpy((*packet)->m_body, bodyData.constData(), tagDataSize);\n    (*packet)->m_headerType = RTMP_PACKET_SIZE_LARGE;\n    (*packet)->m_nTimeStamp = timestamp;\n    (*packet)->m_nBodySize = tagDataSize;\n\n    qDebug() << \"tt:\" << static_cast<unsigned char>(tt[0])\n             << \"ts:\" << timestamp\n             << \"datasize:\" << tagDataSize;\n\n    ret = 1; // 成功\n    return ret;\n}\n```\n\n#### **推流到 RTMP 服务器 (send_data)**  \n   - **功能**: 从 FLV 文件中读取数据并通过 RTMP 协议发送。  \n   - **步骤**:\n     - 创建 `RTMPPacket` 对象。\n     - 逐个读取 FLV 数据包并发送到 RTMP 服务器。\n     - 如果连接断开，则中断发送。\n     - 使用 `RTMP_SendPacket` 发送数据包到 RTMP 服务器。\n\n```cpp\nstatic void send_data(QFile *file, RTMP *rtmp) {\n    RTMPPacket *packet = alloc_packet();\n\n    while(read_data(file, &packet)) {\n        if(!RTMP_IsConnected(rtmp)) {\n            qDebug() << \"Disconnect...\";\n            break;\n        }\n\n        if(!RTMP_SendPacket(rtmp, packet, 0)) {\n            qDebug() << \"Failed to send packet!\";\n        }\n    }\n\n    qDebug() << \"发送结束\";\n}\n```\n\n#### **RTMP 推流整体的封装 (publish_stream)**  \n   - **功能**: 完成 FLV 文件读取、RTMP 连接、数据发送等操作。  \n   - **步骤**:\n     - 打开 FLV 文件并连接到 RTMP 服务器。\n     - 将 FLV 文件中的音视频数据逐个发送到 RTMP 服务器。\n     - 完成推流后，关闭文件。\n\n```cpp\nvoid publish_stream() {\n    char *rtmpaddr = (char *)\"rtmp://127.0.0.1:1935/live/stream01\";\n    QFile *file = openfile((char *)\"output.flv\");\n    if(!file) {\n        return;\n    }\n\n    RTMP *rtmp = connect_rtmp_server(rtmpaddr);\n    if(!rtmp) {\n        return;\n    }\n\n    send_data(file, rtmp);\n    file->close();\n}\n```\n\n#### **线程运行入口 (run)**  \n   - **功能**: 在线程中执行发布流的操作。  \n   - **步骤**:\n     - 初始化 Windows 套接字库 (`WSAStartup`)。\n     - 调用 `publish_stream` 完成推流任务。\n     - 调用 `WSACleanup` 关闭套接字库。\n\n```cpp\nvoid myRtmp::run() {\n    WSADATA wsaData;\n    int result = WSAStartup(MAKEWORD(2, 2), &wsaData);\n    if (result != 0) {\n        qDebug() << \"WSAStartup failed: \" << result;\n        return;\n    }\n    publish_stream();\n    WSACleanup();\n}\n```\n\n### 主要结构和功能：\n- **RTMP 流传输**: 使用 RTMP 协议推送 FLV 文件数据到服务器。\n- **文件处理**: 从 FLV 文件中提取音视频数据并填充到 RTMP 数据包中。\n- **多线程支持**: 使用 `QThread` 在独立线程中执行推流任务。","tags":["FLV","推流","RTMP"],"categories":["音视频"]},{"title":"③实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/02/③实现电脑音频和视频的录制并封装成mp4/","content":"\n### 头文件部分\n\n内容比较少，我就全部放这了, 自己看吧~\n\n```cpp\n#include \"AudioRecorder.h\"\n#include \"videoRecorder.h\"\n\n#include <QMainWindow>\n\nQT_BEGIN_NAMESPACE\nnamespace Ui {\nclass MainWindow;\n}\nQT_END_NAMESPACE\n\nclass MainWindow : public QMainWindow\n{\n    Q_OBJECT\n\npublic:\n    MainWindow(QWidget *parent = nullptr);\n    ~MainWindow();\n\n    int open_device(AVFormatContext **fmt_ctx);\n    int Main_av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt);\n    int Main_avformat_write_header(AVFormatContext *s, AVDictionary **options);\n\nprivate slots:\n    void on_pushButton_clicked();\n\nprivate:\n    Ui::MainWindow *ui;\n    AudioRecorder *aread;\n    VideoRecorder *vread;\n    // create file 设置文件操作对象用于存储消息\n    const char* outFilename = \"output.mp4\";\n    AVFormatContext *ofmt_ctx = nullptr; // 输出上下文\n    QReadWriteLock lock; // 线程安全，读锁 不允许在读取时进行修改; 写锁 不允许在写的时候进行读写 注意读写锁不能包含在同一个作用域里\n};\n```\n\n### 源文件部分\n\n```cpp\n#include \"./ui_mainwindow.h\"\n#include \"mainwindow.h\"\n\nMainWindow::MainWindow(QWidget *parent)\n    : QMainWindow(parent)\n    , ui(new Ui::MainWindow)\n{\n    ui->setupUi(this);\n    aread = new AudioRecorder(this, &ofmt_ctx);\n    vread = new VideoRecorder(this, &ofmt_ctx);\n}\n\nMainWindow::~MainWindow()\n{\n    delete ui;\n}\n\nint MainWindow::Main_av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt)\n{\n    QWriteLocker locker(&lock); // 写锁\n    return av_interleaved_write_frame(s, pkt);\n}\n\nint stream_nb = 0;\n\nint MainWindow::Main_avformat_write_header(AVFormatContext *s, AVDictionary **options)\n{\n    // 写头文件\n    stream_nb += 1;\n    if (stream_nb == 1) {\n        qDebug() << \"等待下一个流\";\n        while (1) {\n            if (stream_nb == 2) return 1;\n        }\n    };\n    return avformat_write_header(ofmt_ctx, NULL);\n};\n\nvoid MainWindow::on_pushButton_clicked()\n{\n    if (!vread->flage) {\n        // 配置输出上下文\n        avformat_alloc_output_context2(&ofmt_ctx, NULL, NULL, outFilename);\n        if (!ofmt_ctx) {\n            qDebug() << \"创建输出上下文失败!\";\n            return;\n        }\n        // 打开输出\n        if (!(ofmt_ctx->oformat->flags & AVFMT_NOFILE)) {\n            // 2.3 创建并初始化一个AVIOContext, 用以访问URL（outFilename）指定的资源\n            if (avio_open(&ofmt_ctx->pb, outFilename, AVIO_FLAG_WRITE) < 0) {\n                qDebug() << \"can't open output URL: %s\\n\" << outFilename;\n                return;\n            }\n        }\n        stream_nb = 0;\n        aread->flage = true;\n        vread->flage = true;\n        aread->start();\n        vread->start();\n        ui->pushButton->setText(\"停止\");\n    } else {\n        aread->flage = false;\n        vread->flage = false;\n        aread->wait();\n        vread->wait();\n        av_write_trailer(ofmt_ctx);\n        /* close output */\n        if (ofmt_ctx && !(ofmt_ctx->oformat->flags & AVFMT_NOFILE)) {\n            avio_closep(&ofmt_ctx->pb);\n        }\n        avformat_free_context(ofmt_ctx);\n        ui->pushButton->setText(\"开始\");\n    }\n}\n```\n---\n\n### **总结**\n通过多线程, 调用FFmpeg的API，音频采集部分利用FIFO缓冲区存储音频数据，视频采集部分直接存放于pFrameYUV，音频经过解码、编码成AAC后进行写入，视频经过解码、编码成H264后进行写入\n第一次写，感觉写的很乱，有很多不足的地方。 有不好的地方可以帮忙指出来 让我偷偷懒吧~~~","tags":["FFmpeg","多线程","QT","音视频录制"],"categories":["音视频"]},{"title":"②实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/02/②实现电脑音频和视频的录制并封装成mp4/","content":"\n\n## VideoRecorder 类详解\n\n### 头文件部分\n\n```cpp\n// 构造函数\nVideoRecorder(QObject* parent = nullptr, AVFormatContext **ofmt_ctx = nullptr);\n\n// 变量\nvoid run() override;\nbool flage = false;\nAVFormatContext *fmt_ctx = NULL; // 输入上下文\nAVFormatContext **ofmt_ctx = NULL; // 输出上下文\nQObject *parent = NULL;\n```\n\n### 源文件部分\n\n采集视频的具体步骤分为9步，涉及以下变量：\n\n```cpp\nAVPacket pkt; // 音频包\nAVPacket *H264pkt = av_packet_alloc();\nAVCodecContext *dec_ctx = NULL;\nAVCodecContext *H264_Codec_ctx = NULL;\nAVFrame *frame = av_frame_alloc();\nAVPacket *newpkt = av_packet_alloc();\nconst char* outFilename = \"output.mp4\"; // 输出文件\n```\n\n#### 步骤 1：打开视频设备\n\n```cpp\nopen_device(&fmt_ctx)\n```\n\n#### 步骤 2：打开视频解码器\n\n```cpp\nopen_video_decoder(fmt_ctx, &dec_ctx)\n```\n\n#### 步骤 3：配置视频编码器并打开\n\n```cpp\nopen_video_encoder(&H264_Codec_ctx, dec_ctx)\n```\n\n#### 步骤 4：创建输出流\n\n```cpp\n// 创建输出流\nAVStream *outStream = avformat_new_stream(*ofmt_ctx, NULL);\navcodec_parameters_from_context(outStream->codecpar, H264_Codec_ctx); // 同样这里也是输出视频流的相关信息\n```\n\n#### 步骤 5：配置图像重采样上下文\n\n```cpp\n// 图像格式转换上下文\nSwsContext* pImgConvertCtx = sws_getContext(dec_ctx->width, dec_ctx->height,\n                                            dec_ctx->pix_fmt, dec_ctx->width, dec_ctx->height,\n                                            AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);\n```\n\n#### 步骤 6：写头文件\n\n```cpp\n// 写头文件\nCallbackFun writehead = std::bind(&MainWindow::Main_avformat_write_header, static_cast<MainWindow *>(parent), *ofmt_ctx, nullptr);\nwritehead();\n```\n\n#### 步骤 7：配置视频数据存储容器 pFrameYUV 及音频帧\n\n```cpp\n// 初始化帧编号\nint64_t pts = 0;\n\nAVFrame *pFrameYUV = av_frame_alloc();\npFrameYUV->format = AV_PIX_FMT_YUV420P;\npFrameYUV->width = dec_ctx->width;\npFrameYUV->height = dec_ctx->height;\nav_frame_get_buffer(pFrameYUV, 0);\n```\n\n#### 步骤 8：读取音频数据并写入文件\n\n```cpp\n// 使用 av_read_frame() 读取音频数据，并写入文件\n```\n\n#### 步骤 9：释放分配的空间\n\n```cpp\n// 释放缓冲区的数据和相关上下文\nif(frame) av_frame_free(&frame);\nif(pFrameYUV) av_frame_free(&pFrameYUV);\nif(newpkt) av_packet_free(&newpkt);\n\nsws_freeContext(pImgConvertCtx);\n\n// 关闭设备并释放 fmt_ctx 资源\navformat_close_input(&fmt_ctx);\n```\n\n### open_device(&fmt_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_device(AVFormatContext **fmt_ctx){\n    const AVInputFormat * iformat = NULL;  // 音频捕获格式\n    AVDictionary *options = NULL;\n    QString devicename;  // 音频设备名称\n\n    // 注册音频设备\n    avdevice_register_all();\n\n    // 获取音频格式\n    iformat = av_find_input_format(\"dshow\");\n\n    // 获取当前音频设备的描述名称\n    // if (avdevice_list_input_sources(iformat, NULL, NULL, &device_list) >= 0) {\n    //     for (int i = 0; i < device_list->nb_devices; i++) {\n    //         qDebug() << \"Device: \" << device_list->devices[i]->device_description << Qt::endl;\n    //         if(i == 1) devicename = \"audio=\" + QString(device_list->devices[i]->device_description);\n    //     }\n    // }\n\n    // video=USB2.0 HD UVC WebCam 摄像头设备名称 || audio=麦克风阵列 (Realtek(R) Audio) 麦克风设备名称\n    // 可以用冒号video=\"Camera\":audio=\"Microphone\" 进行同时使用\n    devicename = \"video=USB2.0 HD UVC WebCam\";\n\n    av_dict_set(&options, \"video_size\", \"1280x720\", 0);\n    // av_dict_set(&options, \"pixel_fmt\", \"yuv420p\", 0);\n    av_dict_set(&options, \"framerate\", \"30\", 0);\n\n    // 打开音频流设备 并初始化上下文\n    if(avformat_open_input(fmt_ctx, devicename.toUtf8(), iformat, &options) < 0){\n        // av_strerror(ret, errors, 1024);\n        // qDebug() << \"Failed to open audio device: \" << ret << errors;\n        return 0;\n    };\n    return 1;\n}\n```\n\n### open_video_decoder(fmt_ctx, &dec_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_video_decoder(AVFormatContext *fmt_ctx, AVCodecContext **dec_ctx){\n    const AVCodec *dec;\n    int ret;\n\n    if((ret = avformat_find_stream_info(fmt_ctx, NULL)) < 0){\n        qDebug() << \"无法获取流信息! \" << ret;\n        return 0;\n    };\n\n    // 选择视频流\n    ret = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, &dec, 0);\n    if(ret < 0){\n        qDebug() << \"无法找到视频流 \" << ret;\n        return 0;\n    }\n\n    int video_stream_index = ret;\n\n    // 创建解码器上下文,并初始化上下文\n    *dec_ctx = avcodec_alloc_context3(dec);\n    if(!*dec_ctx) return 0;\n    avcodec_parameters_to_context(*dec_ctx, fmt_ctx->streams[video_stream_index]->codecpar);\n\n    // 打开解码器\n    if((ret = avcodec_open2(*dec_ctx, dec, nullptr)) < 0){\n        qDebug() << \"解码器打开失败! \" << ret;\n        return 0;\n    };\n\n    return 1;\n}\n```\n\n### open_video_encoder(&H264_Codec_ctx, dec_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_video_encoder(AVCodecContext **H264_Codec_ctx, AVCodecContext *dec_ctx){\n    AVDictionary *options = NULL;\n\n    av_dict_set(&options, \"preset\", \"superfast\", 0);\n    av_dict_set(&options, \"tune\", \"zerolatency\", 0);  // 实现实时编码\n\n    const AVCodec *H264_Codec = avcodec_find_encoder(AV_CODEC_ID_H264);\n    if(!H264_Codec){\n        qDebug() << \"未找到H264编码器!\";\n        return 0;\n    }\n\n    *H264_Codec_ctx = avcodec_alloc_context3(H264_Codec);\n\n    // 设置编码器格式\n    (*H264_Codec_ctx)->codec_id = AV_CODEC_ID_H264; // option\n    (*H264_Codec_ctx)->codec_type = AVMEDIA_TYPE_VIDEO; // option\n    (*H264_Codec_ctx)->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    // 设置SPS/PPS\n    (*H264_Codec_ctx)->profile = FF_PROFILE_H264_HIGH_444; // 压缩等级\n    (*H264_Codec_ctx)->level = 50; // 质量等级为5.0\n\n    // 设置分辨率\n    (*H264_Codec_ctx)->width = dec_ctx->width;\n    (*H264_Codec_ctx)->height = dec_ctx->height;\n\n    // 设置GOP\n    (*H264_Codec_ctx)->gop_size = 250;\n    (*H264_Codec_ctx)->keyint_min = 25; // 最小插入I帧的帧数 在网络丢帧时用于恢复 option\n\n    // 设置B帧数据可减小码流\n    (*H264_Codec_ctx)->max_b_frames = 3; // 可连续的最大B帧数量 option\n    (*H264_Codec_ctx)->has_b_frames = 1; // 指示编码器是否生成 B 帧以及解码器是否需要处理 B 帧 option\n\n    // 设置参考帧数量可提升还原度\n    (*H264_Codec_ctx)->refs = 3; // option\n\n    // 设置帧率\n    (*H264_Codec_ctx)->time_base.num = 1\n\n;\n    (*H264_Codec_ctx)->time_base.den = 30;\n\n    // 设置比特率\n    (*H264_Codec_ctx)->bit_rate = 3420000;\n\n    // 打开编码器\n    if((avcodec_open2(*H264_Codec_ctx, H264_Codec, &options)) < 0){\n        qDebug() << \"H264 编码器打开失败!\";\n        return 0;\n    }\n\n    return 1;\n}\n```\n\n### 数据的读取与写入的具体实现\n\n```cpp\nwhile(flage && av_read_frame(fmt_ctx, &pkt) == 0){\n    int ret = avcodec_send_packet(dec_ctx, &pkt);\n    if(ret < 0) return;\n\n    while(ret >= 0){\n        ret = avcodec_receive_frame(dec_ctx, frame);\n        if(ret < 0){\n            if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break;\n            return;\n        }\n        sws_scale(pImgConvertCtx, (const unsigned char* const*)frame->data, frame->linesize, 0, dec_ctx->height, pFrameYUV->data, pFrameYUV->linesize);\n\n        ret = avcodec_send_frame(H264_Codec_ctx, pFrameYUV);\n        if(ret < 0) return;\n\n        while(ret >= 0){\n            ret = avcodec_receive_packet(H264_Codec_ctx, H264pkt);\n            if(ret < 0){\n                if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break;\n                return;\n            }\n\n            // 编码后PTS、DTS赋值\n            H264pkt->pts = H264pkt->dts = pts * (*ofmt_ctx)->streams[video_stream_index]->time_base.den / (*ofmt_ctx)->streams[video_stream_index]->time_base.num / 30;\n            H264pkt->stream_index = video_stream_index;\n\n            CallbackFun write = std::bind(&MainWindow::Main_av_interleaved_write_frame, static_cast<MainWindow *>(parent), *ofmt_ctx, H264pkt);\n            write();\n\n            pts++;\n            av_packet_unref(H264pkt);\n        }\n        av_frame_unref(frame);\n    }\n    av_packet_unref(&pkt); // Free the packet data after each read\n}\n```","tags":["FFmpeg","音频录制","视频录制","QT","H264"],"categories":["音视频"]},{"title":"①实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/01/①实现电脑音频和视频的录制并封装成mp4/","content":"\n### **音视频录制的多线程实现**\n\n#### **主要类**\n- **AudioRecorder**：音频采集线程\n- **VideoRecorder**：视频采集线程\n- **MainWindow**：控制音频和视频的采集\n\n---\n\n### **AudioRecorder 类详解**\n\n#### **头文件部分**\n- **构造函数**：\n  ```cpp\n  AudioRecorder(QObject *parent = nullptr, AVFormatContext **ofmt_ctx = nullptr);\n  ```\n\n- **主要变量**：\n  - `bool flage = false;`  // 用于控制采集的开始与结束\n  - `AVFormatContext *fmt_ctx = NULL;`  // 输入上下文\n  - `AVFormatContext **ofmt_ctx = NULL;`  // 输出上下文\n  - `QObject *parent = NULL;`  // 用于回调函数\n\n\n#### 源文件部分\n\n采集音频的具体步骤可以分为10个步骤，使用到的变量有：\n\n- `AVPacket pkt;`：音频包\n- `int nb_samples = 22050;`：每帧样本数\n- `SwrContext *swr_ctx = nullptr;`：重采样上下文\n- `uint8_t **src_data = nullptr; uint8_t **dst_data = nullptr;`：音频数据缓冲区\n- `AVCodecContext *codec_ctx = nullptr;`：编码上下文\n- `AVCodecContext *dec_ctx = nullptr;`：解码上下文\n- `AVFrame *frame = av_frame_alloc();`：音频帧\n- `AVAudioFifo* fifo = nullptr;`：音频FIFO缓冲区\n- `const char* outFilename = \"output.mp4\";`：输出文件名\n\n#### **音频采集步骤**\n1. **打开设备**  \n   ```cpp\n   open_device(&fmt_ctx);\n   ```\n\n2. **查找并打开音频解码器**  \n   ```cpp\n   open_Audio_decoder(fmt_ctx, &dec_ctx);\n   ```\n\n3. **打开AAC编码器**  \n   ```cpp\n   open_encoder(&codec_ctx);\n   ```\n\n4. **建立FIFO缓冲区**  \n   ```cpp\n   fifo = init_audio_fifo(codec_ctx->sample_fmt, codec->ch_layout.nb_channels);\n   ```\n\n5. **配置重采样上下文（如果需要，根据编码器的输入要求）**  \n   ```cpp\n   init_resampler(codec_ctx, &swr_ctx, &src_data, &dst_data);\n   ```\n\n6. **创建输出流**  \n   ```cpp\n   AVStream *outStream = avformat_new_stream(*ofmt_ctx, NULL);\n   ```\n\n7. **写头文件（通过回调方式）**\n\n为了确保音频流和视频流都创建好后再写入头文件，我采用了回调函数的方式。FFmpeg在写入头文件时要求所有流都已经创建好，因此我们通过回调机制确保音频流和视频流的创建顺序。\n\n#### **回调函数的实现**\n\n在代码中，我们定义了一个回调函数别名，并将其与`MainWindow`的`Main_avformat_write_header`方法绑定，确保在合适的时机调用该函数来写入头文件。\n\n```cpp\n// 定义回调函数别名，绑定到 MainWindow::Main_avformat_write_header 方法\nCallbackFun writehead = std::bind(&MainWindow::Main_avformat_write_header, \n                                   static_cast<MainWindow *>(parent), \n                                   *ofmt_ctx, nullptr);\n\n// 调用回调函数执行写入头文件操作\nwritehead();\n```\n\n#### **解释**\n\n- `std::bind`：该方法将`MainWindow::Main_avformat_write_header`函数与`parent`（`MainWindow`）对象绑定，并传入必要的参数。\n- 通过回调的方式，只有在音频和视频流都准备好后才会调用`Main_avformat_write_header`方法进行头文件写入，确保FFmpeg正确地写入头文件。\n\n#### **为什么要使用回调**\n\nFFmpeg的`avformat_write_header()`函数要求在写入文件头之前，所有流都必须被创建并初始化。因此，在创建音频和视频流后，我们通过回调函数来确保头文件的写入时机是正确的。\n\n\n8. **配置解码后数据的frame容器及音频帧**\n\n```cpp\n    //获取frame_size\n    const int frame_size = codec_ctx->frame_size;\n    // 初始化帧编号\n    int64_t pts = 0;\n\n    frame->nb_samples = dec_ctx->frame_size;\n    frame->sample_rate = dec_ctx->sample_rate;\n    frame->ch_layout = dec_ctx->ch_layout;\n    frame->format = dec_ctx->sample_fmt;\n```\n\n9. **用 `av_read_frame()` 读取音频数据并写入文件**\n\n\n10. **释放分配的空间**\n\n```cpp\n    // 释放缓冲区的数据和相关上下文\n    if(src_data){\n        av_freep(&src_data[0]);\n        av_freep(&src_data);\n    }\n    if(dst_data){\n        av_freep(&dst_data[0]);\n        av_freep(&dst_data);\n    }\n    if(swr_ctx)swr_free(&swr_ctx);\n    if(frame)av_frame_free(&frame);\n    if(newpkt)av_packet_free(&newpkt);\n    if(fifo)av_audio_fifo_free(fifo);\n\n    // close device and Release fmt_ctx resources 关闭设备并释放上下文\n    avformat_close_input(&fmt_ctx);\n```\n\n---\n\n### **open_device(&fmt_ctx) 的具体实现**\n\n```cpp\nint AudioRecorder::open_device(AVFormatContext **fmt_ctx) {\n    const AVInputFormat * iformat = NULL;  // 音频捕获格式\n    AVDictionary *options = NULL;\n    QString devicename;  // 音频设备名称\n\n    avdevice_register_all();  // 注册音频设备\n\n    // 获取音频格式\n    iformat = av_find_input_format(\"dshow\");\n\n    // 获取当前音频设备的描述名称\n    devicename = \"audio=麦克风阵列 (Realtek(R) Audio)\";\n\n    if (avformat_open_input(fmt_ctx, devicename.toUtf8(), iformat, &options) < 0) {\n        return 0;  // 打开设备失败\n    }\n    return 1;  // 成功打开设备\n}\n```\n\n---\n\n### **open_Audio_decoder() 的具体实现**\n\n```cpp\nint AudioRecorder::open_Audio_decoder(AVFormatContext **fmt_ctx) {\n    const AVCodec *codec = avcodec_find_decoder(AV_CODEC_ID_AAC);\n    if (!codec) {\n        qDebug() << \"音频解码器未找到\";\n        return 0;  // 未找到解码器\n    }\n    \n    // 打开音频解码器\n    if (avcodec_open2(dec_ctx, codec, nullptr) < 0) {\n        qDebug() << \"无法打开解码器\";\n        return 0;\n    }\n    \n    return 1;  // 成功打开解码器\n}\n```\n\n---\n\n### **open_encoder() 的具体实现**\n\n```cpp\nint AudioRecorder::open_encoder(AVCodecContext **codec_ctx) {\n    AVDictionary *options = NULL;\n    const AVCodec *codec = avcodec_find_encoder_by_name(\"libfdk_aac\");\n    if (!codec) {\n        qDebug() << \"编码器 libfdk_aac 未找到\";\n        return 0;\n    }\n\n    // 分配编码器上下文\n    *codec_ctx = avcodec_alloc_context3(codec);\n    if (!*codec_ctx) {\n        qDebug() << \"编码器上下文分配失败\";\n        return 0;\n    }\n\n    // 设置编码器参数\n    AVChannelLayout ch_layout;\n    av_channel_layout_default(&ch_layout, 2);  // 立体声布局\n    (*codec_ctx)->sample_rate = 48000;  // 采样率\n    (*codec_ctx)->sample_fmt = AV_SAMPLE_FMT_S16;  // 样本格式\n    (*codec_ctx)->bit_rate = 128000;  // 比特率\n    if (av_channel_layout_copy(&(*codec_ctx)->ch_layout, &ch_layout) < 0) {\n        qDebug() << \"设置通道布局失败\";\n        return 0;\n    }\n\n    // 打开编码器\n    if (avcodec_open2(*codec_ctx, codec, &options) < 0) {\n        qDebug() << \"编码器打开失败\";\n        return 0;\n    }\n\n    return 1;  // 成功打开编码器\n}\n```\n\n---\n\n### **FIFO缓冲区实现**\n\n```cpp\nAVAudioFifo* AudioRecorder::init_audio_fifo(AVSampleFormat sample_fmt, int channels) {\n    AVAudioFifo* fifo = av_audio_fifo_alloc(sample_fmt, channels, 1);\n    if (!fifo) {\n        qDebug() << \"无法分配FIFO缓冲区\";\n        return nullptr;\n    }\n    return fifo;\n}\n\nint AudioRecorder::write_to_fifo(AVAudioFifo* fifo, const uint8_t** data, int nb_samples) {\n    int ret = av_audio_fifo_write(fifo, (void**)data, nb_samples);\n    if (ret < nb_samples) {\n        qDebug() << \"写入FIFO失败\";\n        return -1;\n    }\n    return 0;  // 成功写入\n}\n\nint AudioRecorder::read_from_fifo(AVAudioFifo* fifo, uint8_t** data, int frame_size) {\n    int ret = av_audio_fifo_read(fifo, (void**)data, frame_size);\n    if (ret < frame_size) {\n        qDebug() << \"从FIFO读取失败\";\n        return -1;\n    }\n    return 0;  // 成功读取\n}\n```\n\n---\n\n### **init_resampler() 的具体实现**\n\n```cpp\nint AudioRecorder::init_resampler(AVCodecContext *codec_ctx, SwrContext **swr_ctx, uint8_t ***src_data, uint8_t ***dst_data) {\n    *swr_ctx = swr_alloc();\n    AVChannelLayout in_ch_layout;\n    av_channel_layout_default(&in_ch_layout, 2);  // 立体声布局\n\n    // 配置重采样上下文\n    swr_alloc_set_opts2(swr_ctx,\n                        &codec_ctx->ch_layout,          // 输出通道布局\n                        codec_ctx->sample_fmt,          // 输出采样格式\n                        codec_ctx->sample_rate,         // 输出采样率\n                        &in_ch_layout,                 // 输入通道布局\n                        AV_SAMPLE_FMT_S16,              // 输入采样格式\n                        48000,                         // 输入采样率\n                        0, nullptr);\n\n    if (!*swr_ctx || swr_init(*swr_ctx) < 0) {\n        qDebug() << \"重采样初始化失败\";\n        return 0;\n    }\n\n    // 创建输入输出缓冲区\n    av_samples_alloc_array_and_samples(src_data, nullptr, in_ch_layout.nb_channels, 22050, AV_SAMPLE_FMT_S16, 0);\n    av_samples_alloc_array_and_samples(dst_data, nullptr, 2, 22050, codec_ctx->sample_fmt, 0);\n    \n    return 1;  // 成功\n}\n```\n\n---\n\n### **音频数据读取与写入文件过程**\n\n```cpp\n //开始获取音频帧数据，并进行转换\n    while (flage && av_read_frame(fmt_ctx, &pkt) == 0) {\n        // qDebug() << \"pkt size: \" << pkt.size;\n        // qDebug() << \"pkt data: \" << pkt.data << Qt::endl;\n\n        //内存拷贝\n        //memcpy(src_data[0], pkt.data, pkt.size); //只使用第一个缓冲区\n        //如果有需要在写入文件之前进行重采样\n        //swr_convert(swr_ctx, dst_data, nb_samples, src_data, nb_samples);\n        int ret = avcodec_send_packet(dec_ctx, &pkt);\n        if(ret < 0){\n            qDebug() << \"向解码器发送数据包失败!\";\n            return;\n        }\n        while(ret >= 0){\n            ret = avcodec_receive_frame(dec_ctx, frame);\n            if(ret < 0){\n                if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                    break;\n                }\n                qDebug() << \"Error, decoding video frame\";\n                return;\n            }\n            // memcpy(src_data[0], frame->data, 22300);\n            // swr_convert(swr_ctx, dst_data, nb_samples, src_data, nb_samples);\n\n            //将样本数据写入 FIFO\n            write_to_fifo(fifo, (const uint8_t**)frame->data, nb_samples);\n            while (av_audio_fifo_size(fifo) >= frame_size) {\n                read_from_fifo(fifo, frame->data, frame_size);\n                frame->nb_samples = codec_ctx->frame_size;\n                frame->pts = pts;\n                ret = avcodec_send_frame(codec_ctx, frame);\n                if(ret < 0){\n                    qDebug() << \"向编码器发送数据包失败!\";\n                    return;\n                }\n                while(ret >= 0){\n                    ret = avcodec_receive_packet(codec_ctx, newpkt);\n                    if(ret < 0){\n                        if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                            break;\n                        }\n                        qDebug() << \"Error, encoding video frame\";\n                        return;\n                    }\n                    newpkt->pts = newpkt->dts = pts;\n                    newpkt->stream_index = audio_stream_index;\n                    //av_interleaved_write_frame(*ofmt_ctx, newpkt);\n                    CallbackFun write = std::bind(&MainWindow::Main_av_interleaved_write_frame, static_cast<MainWindow *>(parent), *ofmt_ctx, newpkt);\n                    write();\n                    av_packet_unref(newpkt);\n                }\n                pts += frame_size;\n            }\n            av_frame_unref(frame);\n        }\n        av_packet_unref(&pkt); // Free the packet data after each read\n    }\n```","tags":["FFmpeg","音频录制","视频录制","多线程","C++","QT"],"categories":["音视频"]},{"title":"SQL基础","url":"/2024/11/28/SQL基础/","content":"\n# 数据库约束与高级操作总结\n\n## 约束\n\n### 概念\n约束是作用于表中字段上的规则，用于限制存储在表中的数据。\n\n**目的**: 保证数据库中数据的正确性、有效性和完整性。\n\n**分类**:\n- **非空约束**: 限制字段数据不能为 NULL  \n  ```sql\n  NOT NULL\n  ```\n\n- **唯一约束**: 保证字段数据唯一、不重复  \n  ```sql\n  UNIQUE\n  ```\n\n- **主键约束**: 主键是行数据的唯一标识，要求非空且唯一  \n  ```sql\n  PRIMARY KEY\n  ```\n\n- **默认约束**: 保存数据时未指定字段值，则采用默认值  \n  ```sql\n  DEFAULT\n  ```\n\n- **检查约束** (8.0.16版本之后): 保证字段值满足条件  \n  ```sql\n  CHECK\n  ```\n\n- **外键约束**: 用来建立表间数据的关联，保证一致性与完整性  \n  ```sql\n  FOREIGN KEY\n  ```\n\n---\n\n### 外键约束\n\n#### 概念\n外键用于在两张表之间建立数据连接，保证数据的一致性和完整性。\n\n#### 语法\n- **添加外键**\n  ```sql\n  CREATE TABLE 表名 (\n    字段名 数据类型,\n    ...\n    [CONSTRAINT 外键名称] FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名)\n  );\n\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名);\n  ```\n\n- **删除外键**\n  ```sql\n  ALTER TABLE 表名 DROP FOREIGN KEY 外键名称;\n  ```\n\n#### 删除/更新行为\n- `NO ACTION`: 检查外键关联，不允许删除/更新。\n- `RESTRICT`: 与 `NO ACTION` 类似，不允许删除/更新。\n- `CASCADE`: 删除/更新父表记录时，同时删除/更新子表记录。\n- `SET NULL`: 删除父表记录时，将子表外键字段设置为 `NULL`。\n- `SET DEFAULT`: 设置子表外键字段为默认值（InnoDB 不支持）。\n\n**示例**:\n```sql\nALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名 (主表字段名) ON UPDATE CASCADE ON DELETE CASCADE;\n```\n\n---\n\n## 多表查询\n\n### 概述\n多表查询指从多张表中获取数据。  \n需要避免无效的 **笛卡尔积**，即两张表中所有数据的组合。\n\n### 多表查询分类\n1. **连接查询**\n   - **内连接**: 获取两张表交集部分的数据。\n   - **左连接**: 获取左表所有数据及交集部分数据。\n   - **右连接**: 获取右表所有数据及交集部分数据。\n   - **自连接**: 表与自身的连接查询，必须使用表别名。\n\n2. **子查询**  \n   在 SQL 语句中嵌套 `SELECT` 语句，称为嵌套查询或子查询。\n\n#### 内连接\n- **隐式内连接**\n  ```sql\n  SELECT 字段列表 FROM 表1, 表2 WHERE 条件;\n  ```\n\n- **显示内连接**\n  ```sql\n  SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;\n  ```\n\n#### 自连接\n自连接是将一张表视为两张表，设置表别名进行查询。\n\n---\n\n## 事务\n\n### 概念\n事务是一组操作的集合，是一个不可分割的工作单位。  \n事务中的所有操作要么全部成功，要么全部失败。\n\n### 事务操作\n- **查看/设置事务提交方式**\n  ```sql\n  SELECT @@autocommit; -- 1 表示自动提交，0 表示手动提交\n\n  SET @@autocommit = 0;\n  ```\n\n- **开启事务**\n  ```sql\n  START TRANSACTION;\n  ```\n\n- **提交事务**\n  ```sql\n  COMMIT;\n  ```\n\n- **回滚事务**\n  ```sql\n  ROLLBACK;\n  ```\n\n### 事务并发问题\n1. **脏读**: 读取到未提交的数据。\n2. **不可重复读**: 一次事务中，数据多次读取结果不同。\n3. **幻读**: 一次事务中新增或删除数据导致总记录数不一致。\n\n### 事务隔离级别\n| 隔离级别           | 脏读 | 不可重复读 | 幻读 |\n|--------------------|-------|------------|-------|\n| Read uncommitted  | 会    | 会         | 会    |\n| Read committed    | 不会  | 会         | 会    |\n| Repeatable Read   | 不会  | 不会       | 会    |\n| Serializable      | 不会  | 不会       | 不会  |\n\n- **查看事务隔离级别**\n  ```sql\n  SELECT @@TRANSACTION_ISOLATION;\n  ```\n\n- **设置事务隔离级别**\n  ```sql\n  SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE};\n  ```","tags":["数据库","SQL","约束","多表查询","事务"],"categories":["SQL"]},{"title":"四种SQL语句","url":"/2024/11/28/四种SQL语句/","content":"\n# 数据库操作与命令总结\n\n## DLL 定义\n\n### 数据库操作\n```sql\nSHOW DATABASES;\n\nCREATE DATABASE 数据库表名;\n\nUSE 数据库名;\n\nSELECT DATABASE(); -- 展示当前所在的数据库\n\nDROP DATABASE 数据库名; -- 删除数据库\n```\n\n### 表操作\n```sql\nSHOW TABLES;\n\nCREATE TABLE 表名 (字段 字段类型, ...);\n\nDESC 表名; -- 查看当前的表结构\n\nSHOW CREATE TABLE 表名;\n\nDROP TABLE 表名;\n```\n\n### 表操作 - 修改\n- **添加字段**\n  ```sql\n  ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释] [约束];\n  ```\n\n- **修改字段类型**\n  ```sql\n  ALTER TABLE 表名 MODIFY 字段名 数据类型(长度);\n  ```\n\n- **修改字段名和字段类型**\n  ```sql\n  ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释] [约束];\n  ```\n\n- **删除字段**\n  ```sql\n  ALTER TABLE 表名 DROP 字段名;\n  ```\n\n- **修改表名**\n  ```sql\n  ALTER TABLE 表名 RENAME TO 新表名;\n  ```\n\n- **删除表**\n  ```sql\n  DROP TABLE [IF EXISTS] 表名;\n  ```\n\n- **删除并重新创建表**\n  ```sql\n  TRUNCATE TABLE 表名;\n  ```\n\n---\n\n## DML 修改\n\n### 添加数据 (INSERT)\n```sql\n-- 给指定字段添加数据\nINSERT INTO 表名 (字段名1, 字段名2...) VALUES (值1, 值2, ...);\n\n-- 给全部字段添加数据\nINSERT INTO 表名 VALUES (值1, 值2, ...);\n\n-- 批量添加数据\nINSERT INTO 表名 (字段名1, 字段名...) VALUES (值1, 值2...), (值1, 值2...), ...;\n\nINSERT INTO 表名 VALUES (值1, 值2...), (值1, 值2...), ...;\n```\n\n### 修改数据 (UPDATE)\n```sql\nUPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ... [WHERE 条件];\n```\n\n### 删除数据 (DELETE)\n```sql\nDELETE FROM 表名 [WHERE 条件];\n-- 注意: 不能删除某个字段的值, 要用 UPDATE;\n```\n\n---\n\n## DQL 查询\n\n### 基本查询\n```sql\n-- 查询多个字段\nSELECT 字段1, 字段2, ... FROM 表名;\n\nSELECT * FROM 表名;\n\n-- 设置别名\nSELECT 字段1 [AS 别名1], 字段2 [AS 别名2], ... FROM 表名;\n\n-- 去除重复记录\nSELECT DISTINCT 字段列表 FROM 表名;\n```\n\n### 条件查询\n```sql\nSELECT 字段列表 FROM 表名 WHERE 条件列表;\n-- 常见条件:\n<> 或 !=      -- 不等于\nBETWEEN ... AND ... -- 在范围内 (含最大最小值)\nIN (...)      -- 在列表中\nLIKE 占位符    -- 模糊匹配 (_匹配单字符, %匹配任意字符)\nIS NULL       -- 是 NULL\n```\n\n### 聚合函数\n```sql\n-- 常见聚合函数:\nCOUNT -- 统计数量\nMAX   -- 最大值\nMIN   -- 最小值\nAVG   -- 平均值\nSUM   -- 求和\n\n-- 使用示例:\nSELECT 聚合函数(字段列表) FROM 表名;\n```\n\n### 分组查询\n```sql\nSELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];\n```\n\n### 排序查询\n```sql\nSELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1, 字段2 排序方式2;\n-- 排序方式:\n-- ASC : 升序 (默认值)\n-- DESC: 降序\n```\n\n### 分页查询\n```sql\nSELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数;\n```\n\n---\n\n## DCL 控制\n\n### 用户管理\n```sql\n-- 查询用户\nUSE mysql;\nSELECT * FROM user;\n\n-- 创建用户\nCREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';\n\n-- 修改用户密码\nALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码';\n\n-- 删除用户\nDROP USER '用户名'@'主机名';\n```\n\n### 权限控制\n- **常用权限**\n  ```text\n  ALL, ALL PRIVILEGES -- 所有权限\n  SELECT              -- 查询数据\n  INSERT              -- 插入数据\n  UPDATE              -- 修改数据\n  DELETE              -- 删除数据\n  ALTER               -- 修改表\n  DROP                -- 删除数据库/表/视图\n  CREATE              -- 创建数据库/表\n  ```\n\n- **查询权限**\n  ```sql\n  SHOW GRANTS FOR '用户名'@'主机名';\n  ```\n\n- **授予权限**\n  ```sql\n  GRANT 权限列表 ON 数据库.表名 TO '用户名'@'主机名';\n  ```\n\n- **撤销权限**\n  ```sql\n  REVOKE 权限列表 ON 数据库.表名 FROM '用户名'@'主机名';\n  ```\n  > 注意: 数据库.表名 可以使用通配符 `*.*` 表示所有数据库的所有表。","tags":["数据库","SQL","命令"],"categories":["SQL"]},{"title":"FFmpeg 基本命令","url":"/2024/11/28/FFmpeg 基本命令/","content":"\n# FFmpeg 使用命令\n\n## 查询可用设备\n```bash\nffmpeg -list_devices true -f dshow -i dummy\n```\n\n---\n\n## 录制\n\n- **摄像头录制**\n  ```bash\n  ffmpeg -f dshow -r 30 -i video=\"USB2.0 HD UVC WebCam\" output.yuv\n  ```\n\n- **麦克风录制**\n  ```bash\n  ffmpeg -f dshow -i audio=\"麦克风阵列 (Realtek(R) Audio)\" output.pcm\n  ```\n\n---\n\n## 播放\n\n- **播放视频**\n  ```bash\n  ffplay -i output.yuv -video_size 1280x720 -framerate 30 -pixel_format yuvj422p\n  ```\n\n- **播放音频**\n  ```bash\n  ffplay -i output.pcm -ar 48000 -f s16le\n  ```\n\n---\n\n## 处理原始数据\n\n- **提取 YUV 视频数据**\n  ```bash\n  ffmpeg -i input.mp4 -an -c:v rawvideo -pixel_format yuv420p out.yuv\n  ```\n\n- **提取 PCM 音频数据**\n  ```bash\n  ffmpeg -i input.mp4 -vn -ar 48000 -channels 2 -f s16le output.pcm\n  ```\n\n---\n\n## 视频滤镜\n\n- **裁剪视频宽高各减 200**\n  ```bash\n  ffmpeg -i input.mp4 -vf crop=in_w-200:in_h-200 -c:v libx264 -c:a copy output.mp4\n  ```\n\n- **从指定时间开始裁剪 10 秒**\n  ```bash\n  ffmpeg -i input.mp4 -ss 00:00:00 -t 10 output.mp4\n  ```\n\n- **拼接多个视频**\n  ```bash\n  ffmpeg -f concat -i input.txt output.mp4\n  ```\n  > `input.txt` 文件内容示例：\n  > ```txt\n  > file 'file1.mp4'\n  > file 'file2.mp4'\n  > ```\n\n---\n\n## 图片与视频转换\n\n- **将视频转换为图片**\n  ```bash\n  ffmpeg -i input.mp4 -r 1 -f image2 image-%3d.jpeg\n  ```\n\n- **将图片转换为视频**\n  ```bash\n  ffmpeg -i image-%3d.jpeg out.mp4\n  ```\n\n# FFprobe 使用命令\n\n## 获取视频帧信息\n  ```bash\n  ffprobe -show_frames -select_streams v:0 -print_format json output.mp4\n  ```\n## 学习中...","tags":["FFmpeg","视频处理","音频处理"],"categories":["音视频"]}]