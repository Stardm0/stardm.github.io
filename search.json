[{"title":"SDL初探","url":"/2024/12/14/SDL初探/","content":"\n学习了一下SDL，跟着教学用SDL实现了一个简单的随机加载红色方块的程序\n\n```c\n#include <stdio.h>\n#include <windows.h>\n#include <SDL.h>\n\nint APIENTRY WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow)\n{\n    int quit = 1;\n    SDL_Event event;\n    SDL_Window *window = NULL;\n    SDL_Renderer *render = NULL;\n    SDL_Texture *texture = NULL;\n\n    SDL_Rect rect;\n    rect.w = 30;\n    rect.h = 30;\n\n    // 初始化 SDL 视频子系统\n    if (SDL_Init(SDL_INIT_VIDEO) != 0) {\n        printf(\"SDL_Init failed: %s\\n\", SDL_GetError());\n        return -1;\n    }\n\n    // 创建窗口\n    window = SDL_CreateWindow(\"Hello World\", SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_CENTERED, 640, 360, SDL_WINDOW_SHOWN);\n    if (!window) {\n        printf(\"Failed to Create Window: %s\\n\", SDL_GetError());\n        goto __EXIT;\n    }\n\n    // 创建渲染器\n    render = SDL_CreateRenderer(window, -1, SDL_RENDERER_ACCELERATED);\n    if (!render) {\n        printf(\"Failed to Create Render: %s\\n\", SDL_GetError());\n        goto __EXIT;\n    }\n\n    // // 设置渲染颜色为红色\n    // SDL_SetRenderDrawColor(render, 255, 0, 0, 255);\n\n    // // 用设置好的颜色刷新屏幕\n    // SDL_RenderClear(render);\n\n    // // 让显示器将新屏幕展示出来\n    // SDL_RenderPresent(render);\n\n    texture = SDL_CreateTexture(render, SDL_PIXELFORMAT_RGBA8888, SDL_TEXTUREACCESS_TARGET, 640, 360);\n    if(!texture){\n        printf(\"Failed to Create Textrue!\");\n        goto __EXIT;\n    }\n    do{\n        SDL_PollEvent(&event);\n        switch(event.type){\n        case SDL_QUIT:\n            quit = 0;\n            break;\n        default:\n            printf(\"event type is %d\", event.type);\n        }\n        rect.x = rand() % 640;\n        rect.y = rand() % 360;\n        SDL_SetRenderTarget(render, texture);\n        SDL_SetRenderDrawColor(render, 0, 0, 0, 255);\n        SDL_RenderClear(render);\n\n        SDL_RenderDrawRect(render, &rect);\n        SDL_SetRenderDrawColor(render, 255, 0, 0, 255);\n        SDL_RenderFillRect(render, &rect);\n\n        SDL_SetRenderTarget(render, NULL);\n        SDL_RenderCopy(render, texture, NULL, NULL);\n        SDL_RenderPresent(render);\n\n    }while(quit);\n\n    // // 等待3秒钟\n    // SDL_Delay(3000);\n\n\n__EXIT:\n    if(window){\n        // 销毁窗口\n        SDL_DestroyWindow(window);\n    }\n    if(render) {\n        // 销毁渲染器\n        SDL_DestroyRenderer(render);\n    }\n    if(texture){\n        // 销毁纹理器\n        SDL_DestroyTexture(texture);\n    }\n\n    SDL_Quit();\n\n    return 0;\n}\n```","tags":["SDL"],"categories":["音视频"]},{"title":"实现FFmpeg的视频转图片(BMP)","url":"/2024/12/13/实现FFmpeg的视频转图片(BMP)/","content":"\n结构体信息可以看这里\nhttps://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapfileheader\n\n这里最容易出错的地方就是这里的\n#pragma pack(push, 1) // 确保结构体对齐方式与 BMP 格式一致\n#pragma pack(pop)\n\n对这个的讲解我这里直接引用了AI的(讲的是真的好（〃｀ 3′〃）)\n### `#pragma pack(push, 1)` 和 `#pragma pack(pop)` 的作用\n\n这两个编译指令用来控制 **结构体成员的对齐方式**，特别是设置如何在内存中排列结构体的数据。  \n\n#### 默认对齐方式\n默认情况下，编译器会对结构体成员进行对齐，以优化内存访问的性能。  \n例如，如果一个结构体成员是 `uint32_t` 类型（4 字节），它通常会对齐到 **4 字节边界**。这样会导致结构体中可能出现一些额外的 **填充字节**（padding），以保证对齐。\n\n例如：\n```c\ntypedef struct {\n    uint8_t a;  // 1 字节\n    uint32_t b; // 4 字节\n} Example;\n\n默认情况下，这个结构体的内存布局是：\n| a | 填充 (3 字节) | b | => 总大小为 8 字节\n```\n\n#### `#pragma pack(push, 1)`\n当使用 `#pragma pack(push, 1)` 时，结构体的成员按 **1 字节对齐**。也就是说，成员会紧密排列，不会插入填充字节。\n\n改用 `#pragma pack(push, 1)` 的情况：\n```c\n#pragma pack(push, 1)\ntypedef struct {\n    uint8_t a;  // 1 字节\n    uint32_t b; // 4 字节\n} Example;\n#pragma pack(pop)\n\n内存布局：\n| a | b | => 总大小为 5 字节\n```\n\n#### 为什么在处理 BMP 文件时使用？\nBMP 文件头和信息头的格式是严格定义的，它们在文件中的每一部分都需要紧密排列，不能有填充字节。  \n例如：\n- `BMPFileHeader` 的大小必须是 14 字节。\n- `BMPInfoHeader` 的大小必须是 40 字节。\n\n如果使用默认对齐方式，结构体可能会包含填充字节，导致文件格式不符合规范。使用 `#pragma pack(push, 1)` 可以确保数据结构的内存布局与 BMP 文件的定义完全一致。\n\n#### `#pragma pack(pop)`\n这个指令用来恢复对齐方式到之前的状态。  \n`#pragma pack(push, 1)` 改变了对齐方式，因此在定义完需要紧密对齐的结构体后，用 `#pragma pack(pop)` 恢复默认对齐方式，以免影响后续代码的性能。\n\n---\n\n#### 总结\n- `#pragma pack(push, 1)` 确保结构体紧密对齐，无填充字节，适合文件格式的定义。\n- `#pragma pack(pop)` 恢复默认对齐方式，避免全局影响。\n- 在处理像 BMP 这种对数据格式严格要求的场景时，显得尤为重要。\n\n### 将视频转BMP图片的案例\n\n```c\n#pragma pack(push, 1) // 确保结构体对齐方式与 BMP 格式一致\n\n// BMP 文件头\ntypedef struct {\n    uint16_t bfType;      // 文件标识符 ('BM')\n    uint32_t bfSize;      // 文件大小\n    uint16_t bfReserved1; // 保留字段\n    uint16_t bfReserved2; // 保留字段\n    uint32_t bfOffBits;   // 数据偏移量\n} BMPFileHeader;\n\n// BMP 信息头\ntypedef struct {\n    uint32_t biSize;          // 信息头大小\n    int32_t  biWidth;         // 图像宽度\n    int32_t  biHeight;        // 图像高度\n    uint16_t biPlanes;        // 颜色平面数（始终为1）\n    uint16_t biBitCount;      // 每像素位数（24位，BGR）\n    uint32_t biCompression;   // 压缩方式（0表示不压缩）\n    uint32_t biSizeImage;     // 图像数据大小\n    int32_t  biXPelsPerMeter; // 水平分辨率（像素/米）\n    int32_t  biYPelsPerMeter; // 垂直分辨率（像素/米）\n    uint32_t biClrUsed;       // 调色板颜色数（0表示无调色板）\n    uint32_t biClrImportant;  // 重要颜色数（0表示所有颜色重要）\n} BMPInfoHeader;\n\n#pragma pack(pop)\n\nvoid saveBMP(unsigned char* buf, int width, int height, int linesize, const char* name) {\n    FILE *f = fopen(name, \"wb\");\n    if (!f) {\n        fprintf(stderr, \"无法打开文件: %s\\n\", name);\n        return;\n    }\n\n    // 初始化 BMP 文件头\n    BMPFileHeader fileHeader = {\n        .bfType = 0x4D42, // 'BM'\n        .bfSize = 0,      // 稍后填充\n        .bfReserved1 = 0,\n        .bfReserved2 = 0,\n        .bfOffBits = sizeof(BMPFileHeader) + sizeof(BMPInfoHeader) // 数据偏移量\n    };\n\n    // 初始化 BMP 信息头\n    BMPInfoHeader infoHeader = {\n        .biSize = sizeof(BMPInfoHeader),\n        .biWidth = width,\n        .biHeight = height, // 注意：正数表示从下到上存储\n        .biPlanes = 1,\n        .biBitCount = 24,\n        .biCompression = 0,\n        .biSizeImage = 0,   // 稍后填充\n        .biXPelsPerMeter = 0,\n        .biYPelsPerMeter = 0,\n        .biClrUsed = 0,\n        .biClrImportant = 0\n    };\n\n    // 计算每行填充的字节数\n    //int row_padded = (width * 3 + 3) & (~3); // 行填充到4字节对齐\n    int image_size = width * height;    // 图像数据总大小\n    fileHeader.bfSize = sizeof(BMPFileHeader) + sizeof(BMPInfoHeader) + image_size;\n    infoHeader.biSizeImage = image_size;\n\n    // 写入文件头和信息头\n    fwrite(&fileHeader, sizeof(BMPFileHeader), 1, f);\n    fwrite(&infoHeader, sizeof(BMPInfoHeader), 1, f);\n\n    // 写入图像数据（从下到上存储）\n    for (int i = height - 1; i >= 0; i--) {\n        fwrite(buf + i * linesize, 1, width * 3, f); // 每个像素3个字节，RGB\n    }\n    fclose(f);\n}\n\n\n\nstatic int decode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, const char* fileName) {\n    int ret = -1;\n    char buf[1024];\n\n    ret = avcodec_send_packet(ctx, pkt);\n    if (ret < 0) {\n        av_log(NULL, AV_LOG_ERROR, \"发送数据包到解码器失败!\\n\");\n        goto _END;\n    }\n\n    while (ret >= 0) {\n        ret = avcodec_receive_frame(ctx, frame);\n        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {\n            return 0;\n        } else if (ret < 0) {\n            return -1;\n        }\n\n        // 创建转换上下文，将YUV转换为RGB\n        struct SwsContext *sws_ctx = sws_getContext(\n            frame->width, frame->height, frame->format,\n            frame->width, frame->height, AV_PIX_FMT_BGR24,\n            SWS_BICUBIC, NULL, NULL, NULL\n        );\n        if (!sws_ctx) {\n            av_log(NULL, AV_LOG_ERROR, \"初始化转换上下文失败\\n\");\n            return -1;\n        }\n\n        // 为RGB数据分配内存\n        uint8_t *rgb_data = (uint8_t *)malloc(frame->width * frame->height * 3); // 每个像素3个字节\n        int rgb_linesize = frame->width * 3;\n\n        // 执行转换\n        sws_scale(sws_ctx, (const uint8_t *const *)frame->data, frame->linesize, 0, frame->height, &rgb_data, &rgb_linesize);\n\n        snprintf(buf, sizeof(buf), \"%s-%d.bmp\", fileName, ctx->frame_num);\n        saveBMP(rgb_data, frame->width, frame->height, rgb_linesize, buf);\n\n        free(rgb_data);\n        sws_freeContext(sws_ctx);\n    }\n\n_END:\n    return 0;\n}\n\n\nint main(int argc, char *argv[])\n{\n    int ret = -1;\n    int idx = -1;\n    // 1. 处理参数\n    char* src;  // 输入数据\n    char* dst;  // 输出数据\n\n    AVFormatContext *pFmtCtx = NULL;\n    AVStream *inStream = NULL;\n\n    const AVCodec *codec = NULL;\n    AVCodecContext *ctx = NULL;\n\n    AVPacket *pkt = NULL;\n    AVFrame *frame = NULL;\n\n    av_log_set_level(AV_LOG_DEBUG);\n    if(argc < 3) {\n        av_log(NULL, AV_LOG_INFO, \"参数数量不足!\\n\");\n        exit(-1);\n    }\n\n    src = argv[1];\n    dst = argv[2];\n\n    // 2. 配置输入上下文，打开多媒体文件\n    if((ret = avformat_open_input(&pFmtCtx, src, NULL, NULL)) < 0){\n        av_log(NULL, AV_LOG_ERROR, \"%s\\n\", av_err2str(ret));\n        exit(-1);\n    }\n\n    // 3. 从多媒体文件中找到视频流\n    idx = av_find_best_stream(pFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);\n    if(idx < 0){\n        av_log(pFmtCtx, AV_LOG_ERROR, \"未找到视频流!\\n\");\n        goto __ERROR;\n    }\n\n    // 4. 查找编码器\n    inStream = pFmtCtx->streams[idx];\n    codec = avcodec_find_decoder(inStream->codecpar->codec_id);\n    if(!codec){\n        av_log(NULL, AV_LOG_ERROR, \"找不到解码器\\n\");\n        goto __ERROR;\n    }\n\n    // 5. 配置编码器上下文\n    ctx = avcodec_alloc_context3(codec);\n    if(!ctx){\n        av_log(NULL, AV_LOG_ERROR, \"内存分配失败\\n\");\n        goto __ERROR;\n    }\n    avcodec_parameters_to_context(ctx, inStream->codecpar);\n\n    // 6. 打开解码器\n    ret = avcodec_open2(ctx, codec, NULL);\n    if(ret < 0){\n        av_log(ctx, AV_LOG_ERROR, \"解码器打开失败: %s\\n\", av_err2str(ret));\n        goto __ERROR;\n    }\n\n    // 7. 创建AVFrame\n    frame = av_frame_alloc();\n    if(!frame){\n        av_log(NULL, AV_LOG_ERROR, \"内存分配失败!\\n\");\n        goto __ERROR;\n    }\n\n    // 8. 创建AVPacket\n    pkt = av_packet_alloc();\n    if(!pkt){\n        av_log(NULL, AV_LOG_ERROR, \"内存分配失败!\\n\");\n        goto __ERROR;\n    }\n\n    // 9. 读取视频数据并保存为图像\n    while(av_read_frame(pFmtCtx, pkt) >= 0){\n        if(pkt->stream_index == idx){\n            decode(ctx, frame, pkt, dst);\n        }\n        av_packet_unref(pkt);\n    }\n\n    decode(ctx, frame, NULL, dst);\n\n    //10. 释放资源\n__ERROR:\n    if(pFmtCtx){\n        avformat_close_input(&pFmtCtx);\n        pFmtCtx = NULL;\n    }\n    if(ctx){\n        avcodec_free_context(&ctx);\n        ctx = NULL;\n    }\n    if(frame){\n        av_frame_free(&frame);\n        frame = NULL;\n    }\n    if(pkt){\n        av_packet_free(&pkt);\n        pkt = NULL;\n    }\n    return 0;\n}\n```","tags":["FFmpeg","BMP"],"categories":["音视频"]},{"title":"用FFmpeg自带的AAC编码器进行编码","url":"/2024/12/11/用FFmpeg自带的AAC编码器进行编码/","content":"\n大体内容和https://stardm.ddns-ip.net/2024/12/01/%E2%91%A2%E5%AE%9E%E7%8E%B0%E7%94%B5%E8%84%91%E9%9F%B3%E9%A2%91%E5%92%8C%E8%A7%86%E9%A2%91%E7%9A%84%E5%BD%95%E5%88%B6%E5%B9%B6%E5%B0%81%E8%A3%85%E6%88%90mp4/ 这一篇的相同，这里主要展示改变有变动的部分\n\n### **音频采集步骤**\n\n这里的序号与`③实现电脑音频和视频的录制并封装成mp4`这篇里的对应\n\n3. **打开AAC编码器**  \n   ```cpp\n   open_encoder(&codec_ctx);\n   ```\n\n4. **配置重采样上下文（主要就是多了这一步）**  \n   ```cpp\n   init_resampler(codec_ctx, &swr_ctx, &src_data, &dst_data);\n   ```\n\n\n8. **配置解码后数据的frame容器及音频帧**\n\n```cpp\n    //获取frame_size\n    const int frame_size = codec_ctx->frame_size;\n    // 初始化帧编号\n    int64_t pts = 0;\n\n    frame->nb_samples = dec_ctx->frame_size;\n    frame->sample_rate = dec_ctx->sample_rate;\n    frame->ch_layout = dec_ctx->ch_layout;\n    frame->format = dec_ctx->sample_fmt;\n\n    av_frame_get_buffer(frame, 0);\n\n    AVFrame *nframe = av_frame_alloc();\n    nframe->nb_samples = codec_ctx->frame_size;\n    nframe->sample_rate = codec_ctx->sample_rate;\n    nframe->ch_layout = codec_ctx->ch_layout;\n    nframe->format = codec_ctx->sample_fmt;\n\n    av_frame_get_buffer(nframe, 0);\n\n    fifo = init_audio_fifo(codec_ctx->sample_fmt, dec_ctx->ch_layout.nb_channels);\n```\n\n9. **用 `av_read_frame()` 读取音频数据并写入文件**\n\n---\n\n### **open_encoder() 的具体实现**\n\n```cpp\nint AudioRecorder::open_encoder(AVCodecContext **codec_ctx) {\n    AVDictionary *options = NULL;\n    const AVCodec *codec = avcodec_find_encoder_by_name(\"aac\"); //这里改成aac\n    if (!codec) {\n        qDebug() << \"编码器 libfdk_aac 未找到\";\n        return 0;\n    }\n\n    // 分配编码器上下文\n    *codec_ctx = avcodec_alloc_context3(codec);\n    if (!*codec_ctx) {\n        qDebug() << \"编码器上下文分配失败\";\n        return 0;\n    }\n\n    // 设置编码器参数\n    AVChannelLayout ch_layout;\n    av_channel_layout_default(&ch_layout, 2);\n    (*codec_ctx)->sample_rate = 48000;\n    (*codec_ctx)->sample_fmt = AV_SAMPLE_FMT_FLTP;  // 样本格式改成FLTP\n    (*codec_ctx)->bit_rate = 128000;\n    if (av_channel_layout_copy(&(*codec_ctx)->ch_layout, &ch_layout) < 0) {\n        qDebug() << \"设置通道布局失败\";\n        return 0;\n    }\n\n    // 打开编码器\n    if (avcodec_open2(*codec_ctx, codec, &options) < 0) {\n        qDebug() << \"编码器打开失败\";\n        return 0;\n    }\n\n    return 1;\n}\n```\n\n---\n\n### **init_resampler() 的具体实现(这里保持不变)**\n\n```cpp\nint AudioRecorder::init_resampler(AVCodecContext *codec_ctx, SwrContext **swr_ctx, uint8_t ***src_data, uint8_t ***dst_data) {\n    *swr_ctx = swr_alloc();\n    AVChannelLayout in_ch_layout;\n    av_channel_layout_default(&in_ch_layout, 2);  // 立体声布局\n\n    // 配置重采样上下文\n    swr_alloc_set_opts2(swr_ctx,\n                        &codec_ctx->ch_layout,          // 输出通道布局\n                        codec_ctx->sample_fmt,          // 输出采样格式\n                        codec_ctx->sample_rate,         // 输出采样率\n                        &in_ch_layout,                 // 输入通道布局\n                        AV_SAMPLE_FMT_S16,              // 输入采样格式\n                        48000,                         // 输入采样率\n                        0, nullptr);\n\n    if (!*swr_ctx || swr_init(*swr_ctx) < 0) {\n        qDebug() << \"重采样初始化失败\";\n        return 0;\n    }\n\n    // 创建输入输出缓冲区\n    av_samples_alloc_array_and_samples(src_data, nullptr, in_ch_layout.nb_channels, 22050, AV_SAMPLE_FMT_S16, 0);\n    av_samples_alloc_array_and_samples(dst_data, nullptr, 2, 22050, codec_ctx->sample_fmt, 0);\n    \n    return 1;  // 成功\n}\n```\n\n---\n\n### **音频数据读取与写入文件过程**\n\n看官方案例就可以知道我这里写的一塌糊涂(不过我也懒得改了(￣﹃￣))\n\n```cpp\n //开始获取音频帧数据，并进行转换\n    while (flage && av_read_frame(fmt_ctx, &pkt) == 0) {\n        int ret = avcodec_send_packet(dec_ctx, &pkt);\n        if(ret < 0){\n            qDebug() << \"向解码器发送数据包失败!\";\n            return;\n        }\n        while(ret >= 0){\n            ret = avcodec_receive_frame(dec_ctx, frame);\n            if(ret < 0){\n                if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                    break;\n                }\n                qDebug() << \"Error, decoding video frame\";\n                return;\n            }\n\n            swr_convert(swr_ctx, dst_data, nb_samples, frame->data, nb_samples);//添加这一步\n\n            //将样本数据写入 FIFO\n            write_to_fifo(fifo, (const uint8_t**)dst_data, nb_samples); //这里的frame改成dst_data\n            while (av_audio_fifo_size(fifo) >= frame_size) {\n                read_from_fifo(fifo, nframe->data, frame_size);\n                nframe->nb_samples = codec_ctx->frame_size;\n                nframe->pts = pts;\n                ret = avcodec_send_frame(codec_ctx, nframe); //还有这个发送的数据包改成nframe\n                if(ret < 0){\n                    qDebug() << \"向编码器发送数据包失败!\";\n                    return;\n                }\n                while(ret >= 0){\n                    ret = avcodec_receive_packet(codec_ctx, newpkt);\n                    if(ret < 0){\n                        if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                            break;\n                        }\n                        qDebug() << \"Error, encoding video frame\";\n                        return;\n                    }\n                    newpkt->pts = newpkt->dts = pts;\n                    newpkt->stream_index = audio_stream_index;\n                    CallbackFun write = std::bind(&MainWindow::Main_av_interleaved_write_frame, static_cast<MainWindow *>(parent), *ofmt_ctx, newpkt);\n                    write();\n                    av_packet_unref(newpkt);\n                }\n                pts += frame_size;\n            }\n            av_frame_unref(frame);\n        }\n        av_packet_unref(&pkt);\n    }\n```\n之前我这里read_from_fifo(fifo, frame->data, frame_size); 之前偷懒，直接用frame。因为没有重采样，所以frame的data数据又是一致的，也就是没有发生改写操作，这样就不会受引用计数的影响，从而不会报错。但就是这么点细节结果让我在用官方AAC编码器上一直写不对(然后就用libfdk_aac了^(*￣(oo)￣)^)","tags":["FFmpeg","AAC"],"categories":["音视频"]},{"title":"Cloudflare证书的颁发切换为 Google Trust(GTS)","url":"/2024/12/10/Cloudflare证书的颁发切换为 Google Trust(GTS)/","content":"\n在使用cloudflare时发现了SSL的证书安全问题，经过一段时间的折腾，证书安全问题倒是解决了。但是我发现cloudflare里SSL显示的有效证书与我网站的真实证书不一致，所以就找到了这个调用官方API的方法。但调用成功后，我发现网站的实际证书还是不一样(很可能是我一开始瞎搞弄成这样的/(ㄒoㄒ)/~~)。总之静观其变吧，看看它续签的时候会不会换回来...(ノへ￣、)\n\n### 通过 API 改变证书(可能需要代理)\n\n#### 输入（适用于 Mac/Linux）：\n\n```bash\ncurl -sX PATCH \"https://api.cloudflare.com/client/v4/zones/[DOMAIN_ZONE_ID_HERE]/ssl/universal/settings\" -H \"X-Auth-Email: [CLOUDFLARE_EMAIL_HERE]\" -H \"X-Auth-Key: [GLOBAL_API_KEY_HERE]\" -H \"Content-Type: application/json\" --data '{\"certificate_authority\":\"google\"}'\n```\n\n#### 或者（对于 Windows）：\n\n```bash\ncurl -sX PATCH \"https://api.cloudflare.com/client/v4/zones/[DOMAIN_ZONE_ID_HERE]/ssl/universal/settings\" -H \"X-Auth-Email: [CLOUDFLARE_EMAIL_HERE]\" -H \"X-Auth-Key: [GLOBAL_API_KEY_HERE]\" -H \"Content-Type: application/json\" --data \"{\\\"certificate_authority\\\":\\\"google\\\"}\"\n```\n\n`[DOMAIN_ZONE_ID_HERE]` 更改为 Zone ID，也就是控制面板显示的那个\n`[CLOUDFLARE_EMAIL_HERE]` 为 Cloudflare 电子邮件地址\n`[GLOBAL_API_KEY_HERE]` 为全局 API 密钥\n`注意不要包含 \"[\" 和 \"]\"`\n\n返回以下内容代表成功\n\n`{\"result\":{\"enabled\":true,\"certificate_authority\":\"google\"},\"success\":true,\"errors\":[],\"messages\":[]}`\n\n#### 查看当前证书(Linux)\n```bash\nopenssl s_client -connect yourdomain.com:443\n```","tags":["解决"],"categories":["杂项"]},{"title":"用FFmpeg实现一个简单小咖秀","url":"/2024/12/09/用FFmpeg实现一个简单小咖秀/","content":"\n### 核心代码\n\n#### 找其中一个源文件的音频流\n```c\nfor(int i = 0; i < ifmt1->nb_streams; i++){\n    AVStream *instream1 = ifmt1->streams[i];\n    AVStream *outstream = NULL;\n    AVCodecParameters *inCodecPar1 = instream1->codecpar;\n\n    if(inCodecPar1->codec_type == AVMEDIA_TYPE_AUDIO){\n        outstream = avformat_new_stream(ofmt, NULL);\n        if(!outstream){\n            av_log(NULL, AV_LOG_ERROR, \"创建流失败!\");\n            goto __ERROR;\n        }\n        avcodec_parameters_copy(outstream->codecpar, instream1->codecpar);\n        outstream->codecpar->codec_tag = 0;\n        aidx = i;\n        aidx1 = cnt++;\n    }\n}\n```\n\n\n#### 找另一个源文件的视频流\n\n```c\nfor(int i = 0; i < ifmt2->nb_streams; i++){\n    AVStream *instream2 = ifmt2->streams[i];\n    AVStream *outstream = NULL;\n    AVCodecParameters *inCodecPar2 = instream2->codecpar;\n\n    if(inCodecPar2->codec_type == AVMEDIA_TYPE_VIDEO){\n        outstream = avformat_new_stream(ofmt, NULL);\n        if(!outstream){\n            av_log(NULL, AV_LOG_ERROR, \"创建流失败!\");\n            goto __ERROR;\n        }\n        avcodec_parameters_copy(outstream->codecpar, instream2->codecpar);\n        outstream->codecpar->codec_tag = 0;\n        vidx = i;\n        vidx1 = cnt++;\n    }\n}\n```\n\n#### 读取源文件并写入到目标文件\n\n```c\nwhile(av_read_frame(ifmt1, &pkt1) >= 0 || av_read_frame(ifmt2, &pkt2) >= 0){\n    if(pkt1.stream_index == aidx){\n        pkt1.pts = av_rescale_q_rnd(pkt1.pts, ifmt1->streams[aidx]->time_base, ofmt->streams[aidx1]->time_base, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));\n        pkt1.dts = pkt1.pts;\n        pkt1.stream_index = aidx1;\n        av_interleaved_write_frame(ofmt, &pkt1);\n        av_packet_unref(&pkt1);\n    }\n    if(pkt2.stream_index == vidx){\n        pkt2.pts = av_rescale_q_rnd(pkt2.pts, ifmt2->streams[vidx]->time_base, ofmt->streams[vidx1]->time_base, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));\n        pkt2.dts = av_rescale_q_rnd(pkt2.dts, ifmt2->streams[vidx]->time_base, ofmt->streams[vidx1]->time_base, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));\n        pkt2.stream_index = vidx1;\n        av_interleaved_write_frame(ofmt, &pkt2);\n        av_packet_unref(&pkt2);        \n    }\n}\n```","tags":["FFmpeg"],"categories":["音视频"]},{"title":"实现FFmpeg的裁剪","url":"/2024/12/08/实现FFmpeg的裁剪/","content":"\n### 核心代码\n\n#### 起始读入位置偏移到与starttime位置最近的后一个帧\n```cpp\nret = av_seek_frame(pFmtCtx, -1, starttime * AV_TIME_BASE, AVSEEK_FLAG_BACKWARD);\nif(ret < 0){\n    av_log(oFmtCtx, AV_LOG_ERROR, \"%s\", av_err2str(ret));\n    goto __ERROR;\n}\n```\n\n#### 申请存储起始读入帧的内存\n```cpp\n    dts_start_time = av_calloc(pFmtCtx->nb_streams, sizeof(int64_t));\n    pts_start_time = av_calloc(pFmtCtx->nb_streams, sizeof(int64_t));\n```\n\n#### 从源多媒体文件中读取数据到目的文件中\n```cpp\nwhile(av_read_frame(pFmtCtx, &pkt) >= 0){\n\n    .....\n\n    //拿到起始读入帧的pts和dts\n    if(pts_start_time[pkt.stream_index] == -1 && pkt.pts > 0 && pkt.dts > 0){\n        pts_start_time[pkt.stream_index] = pkt.pts;\n        dts_start_time[pkt.stream_index] = pkt.dts;\n    }\n\n    //判断是否到达结束时间\n    if((pkt.pts * av_q2d(pFmtCtx->streams[pkt.stream_index]->time_base)) > endtime){\n        av_log(oFmtCtx, AV_LOG_INFO, \"success!\\n\");\n        break;\n    }\n\n    //与开始的帧相减得到相对的pts和dts\n    pkt.pts -= pts_start_time[pkt.stream_index];\n    pkt.dts -= dts_start_time[pkt.stream_index];\n\n    //在含有B帧的情况，编码器会对视频帧进行重排，会导致选择的第一个视频帧的pts大于dts。\n    //这就导致了pts和dts相同的帧，在处理后的pts会小于dts而发生错误, 但对dts的处理是没有问题的\n    //所以在这里将它重新与dts对齐\n    if(pkt.dts > pkt.pts){\n        pkt.pts = pkt.dts;\n    }\n\n    .....\n\n}\n```","tags":["FFmpeg"],"categories":["音视频"]},{"title":"实现FFmpeg的解复用","url":"/2024/12/06/实现FFmpeg的解复用/","content":"\n## 程序步骤\n\n### 1. 处理参数\n```cpp\nchar* src;  //输入数据\nchar* dst;  //输出数据\n\nint *stream_map = NULL;\n\nAVFormatContext *pFmtCtx = NULL;\nAVFormatContext *oFmtCtx = NULL;\n\nAVPacket pkt;\n\nav_log_set_level(AV_LOG_DEBUG);\nif(argc < 3){ //argv[0] 就是这个extra_audio名字\n    av_log(NULL, AV_LOG_INFO, \"arguments must be more than 3!\");\n    exit(-1);\n}\n\nsrc = argv[1];\ndst = argv[2];\n```\n\n---\n\n### 2. 配置输入上下文，打开多媒体文件\n通过 avformat_open_input 打开输入的多媒体文件，并初始化输入上下文：\n```cpp\nif((ret = avformat_open_input(&pFmtCtx, src, NULL, NULL)) < 0){\n    av_log(NULL, AV_LOG_ERROR, \"%s\\n\", av_err2str(ret));\n    exit(-1);\n}\n```\n\n---\n\n### 3. 配置输出上下文\n通过 avformat_alloc_output_context2 为目标文件创建输出上下文：\n```cpp\navformat_alloc_output_context2(&oFmtCtx, NULL, NULL, dst);\nif(!oFmtCtx){\n    av_log(NULL ,AV_LOG_ERROR, \"NO MEMORY\");\n    goto __ERROR;\n}\n```\n\n---\n\n### 4. 打开输出文件\n通过 avio_open2 打开目标文件，用于写入处理后的多媒体数据：\n```cpp\nret = avio_open2(&oFmtCtx->pb, dst, AVIO_FLAG_WRITE, NULL, NULL);\nif(ret < 0){\n    av_log(oFmtCtx, AV_LOG_ERROR, \"%s\", av_err2str(ret));\n    goto __ERROR;\n}\n```\n\n---\n\n### 5. 在输出上下文创建流\n遍历输入文件的所有流，根据需要创建对应的输出流，同时初始化 stream_map：\n```cpp\nstream_map = av_calloc(pFmtCtx->nb_streams, sizeof(int));\nif(!stream_map){\n    av_log(NULL ,AV_LOG_ERROR, \"NO MEMORY\");\n    goto __ERROR;\n}\n\nfor(int i = 0; i < pFmtCtx->nb_streams; i++){\n    AVStream *outStream = NULL;\n    AVStream *inStream = pFmtCtx->streams[i];\n    AVCodecParameters *inCodecPar = inStream->codecpar;\n    if(inCodecPar->codec_type != AVMEDIA_TYPE_AUDIO && inCodecPar->codec_type != AVMEDIA_TYPE_VIDEO && inCodecPar->codec_type != AVMEDIA_TYPE_SUBTITLE){\n        stream_map[i] = -1;\n        continue;\n    }\n    stream_map[i] = stream_idx++;\n    outStream = avformat_new_stream(oFmtCtx, NULL);\n    if(!outStream){\n        av_log(NULL ,AV_LOG_ERROR, \"NO MEMORY\");\n        goto __ERROR;\n    }\n\n    //设置输出视频参数\n    avcodec_parameters_copy(outStream->codecpar, inStream->codecpar);\n    outStream->codecpar->codec_tag = 0; //自动设置编解码器，对于输出流在这里是自动设置编码器\n}\n```\n\n---\n\n### 6. 写多媒体文件头到目的文件\n```cpp\nret = avformat_write_header(oFmtCtx, NULL);\nif(ret < 0){\n    av_log(oFmtCtx, AV_LOG_ERROR, \"%s\", av_err2str(ret));\n    goto __ERROR;\n}\n```\n\n---\n\n### 7. 从源多媒体文件中读取数据到目的文件中\n通过 av_read_frame 读取输入文件的帧数据，并通过 av_interleaved_write_frame 将处理后的数据写入目标文件：\n```cpp\nwhile(av_read_frame(pFmtCtx, &pkt) >= 0){\n    AVStream *inStream, *outStream;\n    if(stream_map[pkt.stream_index] < 0){\n        av_packet_unref(&pkt);\n        continue;\n    }\n    inStream = pFmtCtx->streams[pkt.stream_index];\n    pkt.stream_index = stream_map[pkt.stream_index];\n    outStream = oFmtCtx->streams[pkt.stream_index];\n    av_packet_rescale_ts(&pkt, inStream->time_base, outStream->time_base);\n    //查看ffmpeg源码可以知道在写入包之前会有一个guess_pkt_duration(s, st, pkt),这个函数会自动设置duration\n    //pkt.pos = -1; //用于索引标识，在特殊的场景下可以使用，比如合并多个文件。\n    av_interleaved_write_frame(oFmtCtx, &pkt);\n    av_packet_unref(&pkt);\n}\n```\n\n---\n\n### 8. 写多媒体文件尾到文件中\n```cpp\nav_write_trailer(oFmtCtx);\n```\n\n---\n\n### 9. 将申请的资源释放掉\n```cpp\n__ERROR:\nif(pFmtCtx){\n    avformat_close_input(&pFmtCtx);\n    pFmtCtx = NULL;\n}\nif(oFmtCtx->pb){\n    avio_close(oFmtCtx->pb);\n}\nif(oFmtCtx){\n    avformat_free_context(oFmtCtx);\n    oFmtCtx = NULL;\n}\nif(stream_map){\n    av_free(stream_map);\n}\n```","tags":["FFmpeg"],"categories":["音视频"]},{"title":"对ffmpeg中时间基与时间戳的理解","url":"/2024/12/05/对ffmpeg中时间基与时间戳的理解/","content":"\n### 时间基与时间戳的基本概念\n在 FFmpeg 中，时间基(time_base)是时间戳(timestamp)的单位，时间戳值乘以时间基，可以得到实际的时刻值(以秒等为单位)。\n\n### pts和dts\n这里我将pts和dts简单的理解为`pts是播放时间`，`dts是解码时间`\n视频帧的解码时间和播放时间可能不同，尤其是当视频帧包含B帧时。\n对于I帧，解码时间和播放时间相同。而B帧和P帧的dts和pts就会不一样。\n音频帧的解码时间和播放时间绝大多数的情况下是相同的，因为音频帧按顺序解码并播放。\n\n### 视频流和音频流pts和dts的设置(基于裸流)\n#### 视频流\n`视频按帧播放`，所以解码后的原始视频帧时间基为 1/帧率。  \n对于一般的视频流，时间基的 `num` 和 `den` 为 1 和 90000，时间基就是 1/90000。\n这样计算视频的时间戳就是 `index / 25 * 90000`，`index`是帧标识，表示第几帧。\n即pts就是`index / 25 * 90000`\n而dts我发现不设置也可以(但具体原因我也不知道，有知道的还请一定指点一二，拜托了`(ಥ _ ಥ)`)\n其中，`25` 是视频的帧率（frames per second，fps），即每秒钟的帧数。  \n通过将时间戳乘以时间基，可以得到实际的播放时间。\n换算成时间基的目的，主要是为了统一不视频流的时间单位，就像统一国际单位一样，不同帧率的视频时间戳都有统一的单位。\n这样的换算也能进一步提高精度。\n\n#### 音频流\n`音频按采样点播放`，所以解码后的原始音频帧时间基为 1/采样率。  \n这样音频的时间戳设置就是采样数，时间基就是采样率的倒数。即，采样率越高，每个采样点的时间基就越小。\n\n### 重点\n理解这些最需要记住的一点是：`时间基乘以时间戳得到的是实际时间`。","tags":["FFmpeg"],"categories":["音视频"]},{"title":"解决git操作push失败的问题","url":"/2024/12/04/解决git操作push失败的问题/","content":"\n从网上找到了一个教程，解决了一个烦人的问题\n\n### 设置代理\n```bash\ngit config --global http.proxy http://127.0.0.1:7890  \ngit config --global https.proxy http://127.0.0.1:7890\n```\n\n### 取消和查看代理\n\n#### 取消代理\n```bash\ngit config --global --unset http.proxy  \ngit config --global --unset https.proxy\n```\n\n#### 查看代理\n```bash\ngit config --global --get http.proxy  \ngit config --global --get https.proxy  \ngit config --list\n```\n\n原文链接：[https://blog.csdn.net/Naylor_5/article/details/135648311](https://blog.csdn.net/Naylor_5/article/details/135648311)","tags":["解决","git"],"categories":["杂项"]},{"title":"利用rtmp对本地flv文件进行推流","url":"/2024/12/03/利用rtmp对本地flv文件进行推流/","content":"\n### 实现了从一个 FLV 文件读取音视频数据，并通过 RTMP 协议进行推流。核心步骤包括：\n\n#### **FLV 文件头解析 (openfile)**  \n   - **功能**: 打开并读取 FLV 文件，跳过文件头（9 字节）。  \n   - **步骤**:\n     - 打开指定的 FLV 文件。\n     - 检查文件是否成功打开。如果打开失败，则返回 `nullptr`。\n     - 跳过文件头的 9 字节，定位到数据部分。\n\n```cpp\nstatic QFile *openfile(char *flv_name) {\n    QFile *file = new QFile(flv_name);\n    if(!file->open(QFile::ReadOnly)){\n        qDebug() << \"文件打开失败!\";\n        return nullptr;\n    }\n    file->seek(9); //跳过 9字节 header\n    return file;\n}\n```\n\n#### **RTMP 连接 (connect_rtmp_server)**  \n   - **功能**: 初始化 RTMP 连接到 RTMP 服务器。  \n   - **步骤**:\n     - 检查 RTMP 地址是否为空。\n     - 创建并初始化 RTMP 对象。\n     - 设置 RTMP 服务器地址和连接超时时间。\n     - 进行连接，并设置为推流模式（调用 `RTMP_EnableWrite`）。\n     - 创建并连接流。\n\n```cpp\nstatic RTMP *connect_rtmp_server(char *rtmpaddr) {\n    if(rtmpaddr == NULL){\n        qDebug() << \"连接的RTMP地址为空!\";\n        return NULL;\n    }\n    RTMP *rtmp = nullptr;\n    rtmp = RTMP_Alloc();\n    RTMP_Init(rtmp);\n    if(!rtmp){\n        qDebug() << \"Failed to alloc RTMP object!\";\n        goto __ERROR;\n    }\n\n    RTMP_SetupURL(rtmp, rtmpaddr);\n    rtmp->Link.timeout = 10;\n\n    if(!RTMP_Connect(rtmp, NULL)){\n        qDebug() << \"Failed to connect RTMP Server!\";\n        goto __ERROR;\n    }\n\n    RTMP_EnableWrite(rtmp);\n    RTMP_ConnectStream(rtmp, 0);\n\n    return rtmp;\n__ERROR:\n    if(rtmp){\n        RTMP_Close(rtmp);\n        RTMP_Free(rtmp);\n    }\n    return NULL;\n}\n```\n\n#### **RTMP 数据包分配 (alloc_packet)**  \n   - **功能**: 为 RTMP 数据包分配内存并初始化。  \n   - **步骤**:\n     - 分配 `RTMPPacket` 内存空间。\n     - 分配 64KB 内存空间用于数据包。\n     - 重置数据包并设置初始值。\n\n```cpp\nstatic RTMPPacket *alloc_packet() {\n    RTMPPacket *packet = NULL;\n    packet = (RTMPPacket *)malloc(sizeof(RTMPPacket));\n    if(!packet){\n        qDebug() << \"Failed to alloc RTMPPacket!\";\n        return NULL;\n    }\n\n    RTMPPacket_Alloc(packet, 64 * 1024);\n    RTMPPacket_Reset(packet);\n\n    packet->m_hasAbsTimestamp = 0;\n    packet->m_nChannel = 0x4;\n\n    return packet;\n}\n```\n\n#### **读取 FLV 数据并填充 RTMP 数据包 (read_data)**  \n   - **功能**: 逐个读取 FLV 文件中的数据块并填充 RTMP 数据包。  \n   - **步骤**:\n     - 跳过前 4 字节的 `pre-tag size`。\n     - 读取 tag type、tag data size、时间戳和流 ID。\n     - 读取实际的 tag 数据体，并将其填充到 `RTMPPacket` 中。\n\n```cpp\nstatic int read_data(QFile *file, RTMPPacket **packet) {\n    if (!file || !packet) {\n        qDebug() << \"Error: Invalid arguments.\";\n        return 0;\n    }\n\n    int ret = 0;\n    QByteArray tt, tag_data_size, ts, streamid;\n\n    file->read(4);  // 跳过 pre-tag size\n    tt = file->read(1);  // 读取 tag type\n    tag_data_size = file->read(3);  // 读取 tag data size\n\n    unsigned int tagDataSize = ((unsigned char)tag_data_size[0] << 16)\n                               | ((unsigned char)tag_data_size[1] << 8)\n                               | (unsigned char)tag_data_size[2];\n\n    if (file->bytesAvailable() < tagDataSize) {\n        qDebug() << \"Error: Insufficient data for tag body.\";\n        return 0;\n    }\n\n    ts = file->read(4);  // 读取时间戳\n    unsigned int timestamp = ((unsigned char)ts[0] << 16)\n                             | ((unsigned char)ts[1] << 8)\n                             | ((unsigned char)ts[2]);\n\n    streamid = file->read(3);  // 读取流 ID\n    QByteArray bodyData = file->read(tagDataSize);  // 读取 tag body\n\n    (*packet)->m_packetType = static_cast<unsigned char>(tt[0]);\n    std::memcpy((*packet)->m_body, bodyData.constData(), tagDataSize);\n    (*packet)->m_headerType = RTMP_PACKET_SIZE_LARGE;\n    (*packet)->m_nTimeStamp = timestamp;\n    (*packet)->m_nBodySize = tagDataSize;\n\n    qDebug() << \"tt:\" << static_cast<unsigned char>(tt[0])\n             << \"ts:\" << timestamp\n             << \"datasize:\" << tagDataSize;\n\n    ret = 1; // 成功\n    return ret;\n}\n```\n\n#### **推流到 RTMP 服务器 (send_data)**  \n   - **功能**: 从 FLV 文件中读取数据并通过 RTMP 协议发送。  \n   - **步骤**:\n     - 创建 `RTMPPacket` 对象。\n     - 逐个读取 FLV 数据包并发送到 RTMP 服务器。\n     - 如果连接断开，则中断发送。\n     - 使用 `RTMP_SendPacket` 发送数据包到 RTMP 服务器。\n\n```cpp\nstatic void send_data(QFile *file, RTMP *rtmp) {\n    RTMPPacket *packet = alloc_packet();\n\n    while(read_data(file, &packet)) {\n        if(!RTMP_IsConnected(rtmp)) {\n            qDebug() << \"Disconnect...\";\n            break;\n        }\n\n        if(!RTMP_SendPacket(rtmp, packet, 0)) {\n            qDebug() << \"Failed to send packet!\";\n        }\n    }\n\n    qDebug() << \"发送结束\";\n}\n```\n\n#### **RTMP 推流整体的封装 (publish_stream)**  \n   - **功能**: 完成 FLV 文件读取、RTMP 连接、数据发送等操作。  \n   - **步骤**:\n     - 打开 FLV 文件并连接到 RTMP 服务器。\n     - 将 FLV 文件中的音视频数据逐个发送到 RTMP 服务器。\n     - 完成推流后，关闭文件。\n\n```cpp\nvoid publish_stream() {\n    char *rtmpaddr = (char *)\"rtmp://127.0.0.1:1935/live/stream01\";\n    QFile *file = openfile((char *)\"output.flv\");\n    if(!file) {\n        return;\n    }\n\n    RTMP *rtmp = connect_rtmp_server(rtmpaddr);\n    if(!rtmp) {\n        return;\n    }\n\n    send_data(file, rtmp);\n    file->close();\n}\n```\n\n#### **线程运行入口 (run)**  \n   - **功能**: 在线程中执行发布流的操作。  \n   - **步骤**:\n     - 初始化 Windows 套接字库 (`WSAStartup`)。\n     - 调用 `publish_stream` 完成推流任务。\n     - 调用 `WSACleanup` 关闭套接字库。\n\n```cpp\nvoid myRtmp::run() {\n    WSADATA wsaData;\n    int result = WSAStartup(MAKEWORD(2, 2), &wsaData);\n    if (result != 0) {\n        qDebug() << \"WSAStartup failed: \" << result;\n        return;\n    }\n    publish_stream();\n    WSACleanup();\n}\n```\n\n### 主要结构和功能：\n- **RTMP 流传输**: 使用 RTMP 协议推送 FLV 文件数据到服务器。\n- **文件处理**: 从 FLV 文件中提取音视频数据并填充到 RTMP 数据包中。\n- **多线程支持**: 使用 `QThread` 在独立线程中执行推流任务。","tags":["FLV","推流","RTMP"],"categories":["音视频"]},{"title":"①实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/02/①实现电脑音频和视频的录制并封装成mp4/","content":"\n### 头文件部分\n\n内容比较少，我就全部放这了, 自己看吧~\n\n```cpp\n#include \"AudioRecorder.h\"\n#include \"videoRecorder.h\"\n\n#include <QMainWindow>\n\nQT_BEGIN_NAMESPACE\nnamespace Ui {\nclass MainWindow;\n}\nQT_END_NAMESPACE\n\nclass MainWindow : public QMainWindow\n{\n    Q_OBJECT\n\npublic:\n    MainWindow(QWidget *parent = nullptr);\n    ~MainWindow();\n\n    int open_device(AVFormatContext **fmt_ctx);\n    int Main_av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt);\n    int Main_avformat_write_header(AVFormatContext *s, AVDictionary **options);\n\nprivate slots:\n    void on_pushButton_clicked();\n\nprivate:\n    Ui::MainWindow *ui;\n    AudioRecorder *aread;\n    VideoRecorder *vread;\n    // create file 设置文件操作对象用于存储消息\n    const char* outFilename = \"output.mp4\";\n    AVFormatContext *ofmt_ctx = nullptr; // 输出上下文\n    QReadWriteLock lock; // 线程安全，读锁 不允许在读取时进行修改; 写锁 不允许在写的时候进行读写 注意读写锁不能包含在同一个作用域里\n};\n```\n\n### 源文件部分\n\n```cpp\n#include \"./ui_mainwindow.h\"\n#include \"mainwindow.h\"\n\nMainWindow::MainWindow(QWidget *parent)\n    : QMainWindow(parent)\n    , ui(new Ui::MainWindow)\n{\n    ui->setupUi(this);\n    aread = new AudioRecorder(this, &ofmt_ctx);\n    vread = new VideoRecorder(this, &ofmt_ctx);\n}\n\nMainWindow::~MainWindow()\n{\n    delete ui;\n}\n\nint MainWindow::Main_av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt)\n{\n    QWriteLocker locker(&lock); // 写锁\n    return av_interleaved_write_frame(s, pkt);\n}\n\nint stream_nb = 0;\n\nint MainWindow::Main_avformat_write_header(AVFormatContext *s, AVDictionary **options)\n{\n    // 写头文件\n    stream_nb += 1;\n    if (stream_nb == 1) {\n        qDebug() << \"等待下一个流\";\n        while (1) {\n            if (stream_nb == 2) return 1;\n        }\n    };\n    return avformat_write_header(ofmt_ctx, NULL);\n};\n\nvoid MainWindow::on_pushButton_clicked()\n{\n    if (!vread->flage) {\n        // 配置输出上下文\n        avformat_alloc_output_context2(&ofmt_ctx, NULL, NULL, outFilename);\n        if (!ofmt_ctx) {\n            qDebug() << \"创建输出上下文失败!\";\n            return;\n        }\n        // 打开输出\n        if (!(ofmt_ctx->oformat->flags & AVFMT_NOFILE)) {\n            // 2.3 创建并初始化一个AVIOContext, 用以访问URL（outFilename）指定的资源\n            if (avio_open(&ofmt_ctx->pb, outFilename, AVIO_FLAG_WRITE) < 0) {\n                qDebug() << \"can't open output URL: %s\\n\" << outFilename;\n                return;\n            }\n        }\n        stream_nb = 0;\n        aread->flage = true;\n        vread->flage = true;\n        aread->start();\n        vread->start();\n        ui->pushButton->setText(\"停止\");\n    } else {\n        aread->flage = false;\n        vread->flage = false;\n        aread->wait();\n        vread->wait();\n        av_write_trailer(ofmt_ctx);\n        /* close output */\n        if (ofmt_ctx && !(ofmt_ctx->oformat->flags & AVFMT_NOFILE)) {\n            avio_closep(&ofmt_ctx->pb);\n        }\n        avformat_free_context(ofmt_ctx);\n        ui->pushButton->setText(\"开始\");\n    }\n}\n```\n---\n\n### **总结**\n通过多线程, 调用FFmpeg的API，音频采集部分利用FIFO缓冲区存储音频数据，视频采集部分直接存放于pFrameYUV，音频经过解码、编码成AAC后进行写入，视频经过解码、编码成H264后进行写入\n第一次写，感觉写的很乱，有很多不足的地方。 有不好的地方可以帮忙指出来 让我偷偷懒吧~~~","tags":["FFmpeg","QT","多线程","C++"],"categories":["音视频"]},{"title":"②实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/02/②实现电脑音频和视频的录制并封装成mp4/","content":"\n\n## VideoRecorder 类详解\n\n### 头文件部分\n\n```cpp\n// 构造函数\nVideoRecorder(QObject* parent = nullptr, AVFormatContext **ofmt_ctx = nullptr);\n\n// 变量\nvoid run() override;\nbool flage = false;\nAVFormatContext *fmt_ctx = NULL; // 输入上下文\nAVFormatContext **ofmt_ctx = NULL; // 输出上下文\nQObject *parent = NULL;\n```\n\n### 源文件部分\n\n采集视频的具体步骤分为9步，涉及以下变量：\n\n```cpp\nAVPacket pkt; // 音频包\nAVPacket *H264pkt = av_packet_alloc();\nAVCodecContext *dec_ctx = NULL;\nAVCodecContext *H264_Codec_ctx = NULL;\nAVFrame *frame = av_frame_alloc();\nAVPacket *newpkt = av_packet_alloc();\nconst char* outFilename = \"output.mp4\"; // 输出文件\n```\n\n#### 步骤 1：打开视频设备\n\n```cpp\nopen_device(&fmt_ctx)\n```\n\n#### 步骤 2：打开视频解码器\n\n```cpp\nopen_video_decoder(fmt_ctx, &dec_ctx)\n```\n\n#### 步骤 3：配置视频编码器并打开\n\n```cpp\nopen_video_encoder(&H264_Codec_ctx, dec_ctx)\n```\n\n#### 步骤 4：创建输出流\n\n```cpp\n// 创建输出流\nAVStream *outStream = avformat_new_stream(*ofmt_ctx, NULL);\navcodec_parameters_from_context(outStream->codecpar, H264_Codec_ctx); // 同样这里也是输出视频流的相关信息\n```\n\n#### 步骤 5：配置图像重采样上下文\n\n```cpp\n// 图像格式转换上下文\nSwsContext* pImgConvertCtx = sws_getContext(dec_ctx->width, dec_ctx->height,\n                                            dec_ctx->pix_fmt, dec_ctx->width, dec_ctx->height,\n                                            AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);\n```\n\n#### 步骤 6：写头文件\n\n```cpp\n// 写头文件\nCallbackFun writehead = std::bind(&MainWindow::Main_avformat_write_header, static_cast<MainWindow *>(parent), *ofmt_ctx, nullptr);\nwritehead();\n```\n\n#### 步骤 7：配置视频数据存储容器 pFrameYUV\n\n```cpp\n// 初始化帧编号\nint64_t pts = 0;\n\nAVFrame *pFrameYUV = av_frame_alloc();\npFrameYUV->format = AV_PIX_FMT_YUV420P;\npFrameYUV->width = dec_ctx->width;\npFrameYUV->height = dec_ctx->height;\nav_frame_get_buffer(pFrameYUV, 0);\n```\n\n#### 步骤 8：读取数据并写入文件\n\n```cpp\n// 使用 av_read_frame() 读取音频数据，并写入文件\n```\n\n#### 步骤 9：释放分配的空间\n\n```cpp\n// 释放缓冲区的数据和相关上下文\nif(frame) av_frame_free(&frame);\nif(pFrameYUV) av_frame_free(&pFrameYUV);\nif(newpkt) av_packet_free(&newpkt);\n\nsws_freeContext(pImgConvertCtx);\n\n// 关闭设备并释放 fmt_ctx 资源\navformat_close_input(&fmt_ctx);\n```\n\n### open_device(&fmt_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_device(AVFormatContext **fmt_ctx){\n    const AVInputFormat * iformat = NULL;  // 音视频捕获格式\n    AVDictionary *options = NULL;\n    QString devicename;  // 音视频设备名称\n\n    // 注册音视频设备\n    avdevice_register_all();\n\n    // 获取音视频格式\n    iformat = av_find_input_format(\"dshow\");\n\n    // 获取当前音视频设备的描述名称\n    // if (avdevice_list_input_sources(iformat, NULL, NULL, &device_list) >= 0) {\n    //     for (int i = 0; i < device_list->nb_devices; i++) {\n    //         qDebug() << \"Device: \" << device_list->devices[i]->device_description << Qt::endl;\n    //         if(i == 1) devicename = \"audio=\" + QString(device_list->devices[i]->device_description);\n    //     }\n    // }\n\n    // video=USB2.0 HD UVC WebCam 摄像头设备名称 || audio=麦克风阵列 (Realtek(R) Audio) 麦克风设备名称\n    // 可以用冒号video=\"Camera\":audio=\"Microphone\" 进行同时使用\n    devicename = \"video=USB2.0 HD UVC WebCam\";\n\n    av_dict_set(&options, \"video_size\", \"1280x720\", 0);\n    // av_dict_set(&options, \"pixel_fmt\", \"yuv420p\", 0);\n    av_dict_set(&options, \"framerate\", \"30\", 0);\n\n    // 打开视频流设备 并初始化上下文\n    if(avformat_open_input(fmt_ctx, devicename.toUtf8(), iformat, &options) < 0){\n        // av_strerror(ret, errors, 1024);\n        // qDebug() << \"Failed to open audio device: \" << ret << errors;\n        return 0;\n    };\n    return 1;\n}\n```\n\n### open_video_decoder(fmt_ctx, &dec_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_video_decoder(AVFormatContext *fmt_ctx, AVCodecContext **dec_ctx){\n    const AVCodec *dec;\n    int ret;\n\n    if((ret = avformat_find_stream_info(fmt_ctx, NULL)) < 0){\n        qDebug() << \"无法获取流信息! \" << ret;\n        return 0;\n    };\n\n    // 选择视频流\n    ret = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, &dec, 0);\n    if(ret < 0){\n        qDebug() << \"无法找到视频流 \" << ret;\n        return 0;\n    }\n\n    int video_stream_index = ret;\n\n    // 创建解码器上下文,并初始化上下文\n    *dec_ctx = avcodec_alloc_context3(dec);\n    if(!*dec_ctx) return 0;\n    avcodec_parameters_to_context(*dec_ctx, fmt_ctx->streams[video_stream_index]->codecpar);\n\n    // 打开解码器\n    if((ret = avcodec_open2(*dec_ctx, dec, nullptr)) < 0){\n        qDebug() << \"解码器打开失败! \" << ret;\n        return 0;\n    };\n\n    return 1;\n}\n```\n\n### open_video_encoder(&H264_Codec_ctx, dec_ctx)的具体实现\n\n```cpp\nint VideoRecorder::open_video_encoder(AVCodecContext **H264_Codec_ctx, AVCodecContext *dec_ctx){\n    AVDictionary *options = NULL;\n\n    av_dict_set(&options, \"preset\", \"superfast\", 0);\n    av_dict_set(&options, \"tune\", \"zerolatency\", 0);  // 实现实时编码\n\n    const AVCodec *H264_Codec = avcodec_find_encoder(AV_CODEC_ID_H264);\n    if(!H264_Codec){\n        qDebug() << \"未找到H264编码器!\";\n        return 0;\n    }\n\n    *H264_Codec_ctx = avcodec_alloc_context3(H264_Codec);\n\n    // 设置编码器格式\n    (*H264_Codec_ctx)->codec_id = AV_CODEC_ID_H264; // option\n    (*H264_Codec_ctx)->codec_type = AVMEDIA_TYPE_VIDEO; // option\n    (*H264_Codec_ctx)->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    // 设置SPS/PPS\n    (*H264_Codec_ctx)->profile = FF_PROFILE_H264_HIGH_444; // 压缩等级\n    (*H264_Codec_ctx)->level = 50; // 质量等级为5.0\n\n    // 设置分辨率\n    (*H264_Codec_ctx)->width = dec_ctx->width;\n    (*H264_Codec_ctx)->height = dec_ctx->height;\n\n    // 设置GOP\n    (*H264_Codec_ctx)->gop_size = 250;\n    (*H264_Codec_ctx)->keyint_min = 25; // 最小插入I帧的帧数 在网络丢帧时用于恢复 option\n\n    // 设置B帧数据可减小码流\n    (*H264_Codec_ctx)->max_b_frames = 3; // 可连续的最大B帧数量 option\n    (*H264_Codec_ctx)->has_b_frames = 1; // 指示编码器是否生成 B 帧以及解码器是否需要处理 B 帧 option\n\n    // 设置参考帧数量可提升还原度\n    (*H264_Codec_ctx)->refs = 3; // option\n\n    // 设置帧率\n    (*H264_Codec_ctx)->time_base.num = 1\n\n;\n    (*H264_Codec_ctx)->time_base.den = 30;\n\n    // 设置比特率\n    (*H264_Codec_ctx)->bit_rate = 3420000;\n\n    // 打开编码器\n    if((avcodec_open2(*H264_Codec_ctx, H264_Codec, &options)) < 0){\n        qDebug() << \"H264 编码器打开失败!\";\n        return 0;\n    }\n\n    return 1;\n}\n```\n\n### 数据的读取与写入的具体实现\n\n```cpp\nwhile(flage && av_read_frame(fmt_ctx, &pkt) == 0){\n    int ret = avcodec_send_packet(dec_ctx, &pkt);\n    if(ret < 0) return;\n\n    while(ret >= 0){\n        ret = avcodec_receive_frame(dec_ctx, frame);\n        if(ret < 0){\n            if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break;\n            return;\n        }\n        sws_scale(pImgConvertCtx, (const unsigned char* const*)frame->data, frame->linesize, 0, dec_ctx->height, pFrameYUV->data, pFrameYUV->linesize);\n\n        ret = avcodec_send_frame(H264_Codec_ctx, pFrameYUV);\n        if(ret < 0) return;\n\n        while(ret >= 0){\n            ret = avcodec_receive_packet(H264_Codec_ctx, H264pkt);\n            if(ret < 0){\n                if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break;\n                return;\n            }\n\n            // 编码后PTS、DTS赋值\n            H264pkt->pts = H264pkt->dts = pts * (*ofmt_ctx)->streams[video_stream_index]->time_base.den / (*ofmt_ctx)->streams[video_stream_index]->time_base.num / 30;\n            H264pkt->stream_index = video_stream_index;\n\n            CallbackFun write = std::bind(&MainWindow::Main_av_interleaved_write_frame, static_cast<MainWindow *>(parent), *ofmt_ctx, H264pkt);\n            write();\n\n            pts++;\n            av_packet_unref(H264pkt);\n        }\n        av_frame_unref(frame);\n    }\n    av_packet_unref(&pkt); // Free the packet data after each read\n}\n```","tags":["FFmpeg","QT","H264"],"categories":["音视频"]},{"title":"③实现电脑音频和视频的录制并封装成mp4","url":"/2024/12/01/③实现电脑音频和视频的录制并封装成mp4/","content":"\n### **音视频录制的多线程实现**\n\n#### **主要类**\n- **AudioRecorder**：音频采集线程\n- **VideoRecorder**：视频采集线程\n- **MainWindow**：控制音频和视频的采集\n\n---\n\n### **AudioRecorder 类详解**\n\n#### **头文件部分**\n- **构造函数**：\n  ```cpp\n  AudioRecorder(QObject *parent = nullptr, AVFormatContext **ofmt_ctx = nullptr);\n  ```\n\n- **主要变量**：\n  - `bool flage = false;`  // 用于控制采集的开始与结束\n  - `AVFormatContext *fmt_ctx = NULL;`  // 输入上下文\n  - `AVFormatContext **ofmt_ctx = NULL;`  // 输出上下文\n  - `QObject *parent = NULL;`  // 用于回调函数\n\n\n#### 源文件部分\n\n采集音频的具体步骤可以分为10个步骤，使用到的变量有：\n\n- `AVPacket pkt;`：音频包\n- `int nb_samples = 22050;`：每帧样本数\n- `SwrContext *swr_ctx = nullptr;`：重采样上下文\n- `uint8_t **src_data = nullptr; uint8_t **dst_data = nullptr;`：音频数据缓冲区\n- `AVCodecContext *codec_ctx = nullptr;`：编码上下文\n- `AVCodecContext *dec_ctx = nullptr;`：解码上下文\n- `AVFrame *frame = av_frame_alloc();`：音频帧\n- `AVAudioFifo* fifo = nullptr;`：音频FIFO缓冲区\n- `const char* outFilename = \"output.mp4\";`：输出文件名\n\n#### **音频采集步骤**\n1. **打开设备**  \n   ```cpp\n   open_device(&fmt_ctx);\n   ```\n\n2. **查找并打开音频解码器**  \n   ```cpp\n   open_Audio_decoder(fmt_ctx, &dec_ctx);\n   ```\n\n3. **打开AAC编码器**  \n   ```cpp\n   open_encoder(&codec_ctx);\n   ```\n\n4. **建立FIFO缓冲区**  \n   ```cpp\n   fifo = init_audio_fifo(codec_ctx->sample_fmt, codec->ch_layout.nb_channels);\n   ```\n\n5. **配置重采样上下文（如果需要，根据编码器的输入要求）**  \n   ```cpp\n   init_resampler(codec_ctx, &swr_ctx, &src_data, &dst_data);\n   ```\n\n6. **创建输出流**  \n   ```cpp\n   AVStream *outStream = avformat_new_stream(*ofmt_ctx, NULL);\n   ```\n\n7. **写头文件（通过回调方式）**\n\n为了确保音频流和视频流都创建好后再写入头文件，我采用了回调函数的方式。FFmpeg在写入头文件时要求所有流都已经创建好，因此我们通过回调机制确保音频流和视频流的创建顺序。\n\n#### **回调函数的实现**\n\n在代码中，我们定义了一个回调函数别名，并将其与`MainWindow`的`Main_avformat_write_header`方法绑定，确保在合适的时机调用该函数来写入头文件。\n\n```cpp\n// 定义回调函数别名，绑定到 MainWindow::Main_avformat_write_header 方法\nCallbackFun writehead = std::bind(&MainWindow::Main_avformat_write_header, \n                                   static_cast<MainWindow *>(parent), \n                                   *ofmt_ctx, nullptr);\n\n// 调用回调函数执行写入头文件操作\nwritehead();\n```\n\n#### **解释**\n\n- `std::bind`：该方法将`MainWindow::Main_avformat_write_header`函数与`parent`（`MainWindow`）对象绑定，并传入必要的参数。\n- 通过回调的方式，只有在音频和视频流都准备好后才会调用`Main_avformat_write_header`方法进行头文件写入，确保FFmpeg正确地写入头文件。\n\n#### **为什么要使用回调**\n\nFFmpeg的`avformat_write_header()`函数要求在写入文件头之前，所有流都必须被创建并初始化。因此，在创建音频和视频流后，我们通过回调函数来确保头文件的写入时机是正确的。\n\n\n8. **配置解码后数据的frame容器及音频帧**\n\n```cpp\n    //获取frame_size\n    const int frame_size = codec_ctx->frame_size;\n    // 初始化帧编号\n    int64_t pts = 0;\n\n    frame->nb_samples = dec_ctx->frame_size;\n    frame->sample_rate = dec_ctx->sample_rate;\n    frame->ch_layout = dec_ctx->ch_layout;\n    frame->format = dec_ctx->sample_fmt;\n```\n\n9. **用 `av_read_frame()` 读取音频数据并写入文件**\n\n\n10. **释放分配的空间**\n\n```cpp\n    // 释放缓冲区的数据和相关上下文\n    if(src_data){\n        av_freep(&src_data[0]);\n        av_freep(&src_data);\n    }\n    if(dst_data){\n        av_freep(&dst_data[0]);\n        av_freep(&dst_data);\n    }\n    if(swr_ctx)swr_free(&swr_ctx);\n    if(frame)av_frame_free(&frame);\n    if(newpkt)av_packet_free(&newpkt);\n    if(fifo)av_audio_fifo_free(fifo);\n\n    // close device and Release fmt_ctx resources 关闭设备并释放上下文\n    avformat_close_input(&fmt_ctx);\n```\n\n---\n\n### **open_device(&fmt_ctx) 的具体实现**\n\n```cpp\nint AudioRecorder::open_device(AVFormatContext **fmt_ctx) {\n    const AVInputFormat * iformat = NULL;  // 音视频捕获格式\n    AVDictionary *options = NULL;\n    QString devicename;  // 音视频设备名称\n\n    avdevice_register_all();  // 注册音视频设备\n\n    // 获取音视频格式\n    iformat = av_find_input_format(\"dshow\");\n\n    // 获取当前音频设备的描述名称\n    devicename = \"audio=麦克风阵列 (Realtek(R) Audio)\";\n\n    if (avformat_open_input(fmt_ctx, devicename.toUtf8(), iformat, &options) < 0) {\n        return 0;  // 打开设备失败\n    }\n    return 1;  // 成功打开设备\n}\n```\n\n---\n\n### **open_Audio_decoder() 的具体实现**\n\n```cpp\nint AudioRecorder::open_Audio_decoder(AVFormatContext **fmt_ctx) {\n    const AVCodec *codec = avcodec_find_decoder(AV_CODEC_ID_AAC);\n    if (!codec) {\n        qDebug() << \"音频解码器未找到\";\n        return 0;  // 未找到解码器\n    }\n    \n    // 打开音频解码器\n    if (avcodec_open2(dec_ctx, codec, nullptr) < 0) {\n        qDebug() << \"无法打开解码器\";\n        return 0;\n    }\n    \n    return 1;  // 成功打开解码器\n}\n```\n\n---\n\n### **open_encoder() 的具体实现**\n\n```cpp\nint AudioRecorder::open_encoder(AVCodecContext **codec_ctx) {\n    AVDictionary *options = NULL;\n    const AVCodec *codec = avcodec_find_encoder_by_name(\"libfdk_aac\");\n    if (!codec) {\n        qDebug() << \"编码器 libfdk_aac 未找到\";\n        return 0;\n    }\n\n    // 分配编码器上下文\n    *codec_ctx = avcodec_alloc_context3(codec);\n    if (!*codec_ctx) {\n        qDebug() << \"编码器上下文分配失败\";\n        return 0;\n    }\n\n    // 设置编码器参数\n    AVChannelLayout ch_layout;\n    av_channel_layout_default(&ch_layout, 2);  // 立体声布局\n    (*codec_ctx)->sample_rate = 48000;  // 采样率\n    (*codec_ctx)->sample_fmt = AV_SAMPLE_FMT_S16;  // 样本格式\n    (*codec_ctx)->bit_rate = 128000;  // 比特率\n    if (av_channel_layout_copy(&(*codec_ctx)->ch_layout, &ch_layout) < 0) {\n        qDebug() << \"设置通道布局失败\";\n        return 0;\n    }\n\n    // 打开编码器\n    if (avcodec_open2(*codec_ctx, codec, &options) < 0) {\n        qDebug() << \"编码器打开失败\";\n        return 0;\n    }\n\n    return 1;  // 成功打开编码器\n}\n```\n\n---\n\n### **FIFO缓冲区实现**\n\n```cpp\nAVAudioFifo* AudioRecorder::init_audio_fifo(AVSampleFormat sample_fmt, int channels) {\n    AVAudioFifo* fifo = av_audio_fifo_alloc(sample_fmt, channels, 1);\n    if (!fifo) {\n        qDebug() << \"无法分配FIFO缓冲区\";\n        return nullptr;\n    }\n    return fifo;\n}\n\nint AudioRecorder::write_to_fifo(AVAudioFifo* fifo, const uint8_t** data, int nb_samples) {\n    int ret = av_audio_fifo_write(fifo, (void**)data, nb_samples);\n    if (ret < nb_samples) {\n        qDebug() << \"写入FIFO失败\";\n        return -1;\n    }\n    return 0;  // 成功写入\n}\n\nint AudioRecorder::read_from_fifo(AVAudioFifo* fifo, uint8_t** data, int frame_size) {\n    int ret = av_audio_fifo_read(fifo, (void**)data, frame_size);\n    if (ret < frame_size) {\n        qDebug() << \"从FIFO读取失败\";\n        return -1;\n    }\n    return 0;  // 成功读取\n}\n```\n\n---\n\n### **init_resampler() 的具体实现**\n\n```cpp\nint AudioRecorder::init_resampler(AVCodecContext *codec_ctx, SwrContext **swr_ctx, uint8_t ***src_data, uint8_t ***dst_data) {\n    *swr_ctx = swr_alloc();\n    AVChannelLayout in_ch_layout;\n    av_channel_layout_default(&in_ch_layout, 2);  // 立体声布局\n\n    // 配置重采样上下文\n    swr_alloc_set_opts2(swr_ctx,\n                        &codec_ctx->ch_layout,          // 输出通道布局\n                        codec_ctx->sample_fmt,          // 输出采样格式\n                        codec_ctx->sample_rate,         // 输出采样率\n                        &in_ch_layout,                 // 输入通道布局\n                        AV_SAMPLE_FMT_S16,              // 输入采样格式\n                        48000,                         // 输入采样率\n                        0, nullptr);\n\n    if (!*swr_ctx || swr_init(*swr_ctx) < 0) {\n        qDebug() << \"重采样初始化失败\";\n        return 0;\n    }\n\n    // 创建输入输出缓冲区\n    av_samples_alloc_array_and_samples(src_data, nullptr, in_ch_layout.nb_channels, 22050, AV_SAMPLE_FMT_S16, 0);\n    av_samples_alloc_array_and_samples(dst_data, nullptr, 2, 22050, codec_ctx->sample_fmt, 0);\n    \n    return 1;  // 成功\n}\n```\n\n---\n\n### **音频数据读取与写入文件过程**\n\n```cpp\n //开始获取音频帧数据，并进行转换\n    while (flage && av_read_frame(fmt_ctx, &pkt) == 0) {\n        // qDebug() << \"pkt size: \" << pkt.size;\n        // qDebug() << \"pkt data: \" << pkt.data << Qt::endl;\n\n        //内存拷贝\n        //memcpy(src_data[0], pkt.data, pkt.size); //只使用第一个缓冲区\n        //如果有需要在写入文件之前进行重采样\n        //swr_convert(swr_ctx, dst_data, nb_samples, src_data, nb_samples);\n        int ret = avcodec_send_packet(dec_ctx, &pkt);\n        if(ret < 0){\n            qDebug() << \"向解码器发送数据包失败!\";\n            return;\n        }\n        while(ret >= 0){\n            ret = avcodec_receive_frame(dec_ctx, frame);\n            if(ret < 0){\n                if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                    break;\n                }\n                qDebug() << \"Error, decoding video frame\";\n                return;\n            }\n            // memcpy(src_data[0], frame->data, 22300);\n            // swr_convert(swr_ctx, dst_data, nb_samples, src_data, nb_samples);\n\n            //将样本数据写入 FIFO\n            write_to_fifo(fifo, (const uint8_t**)frame->data, nb_samples);\n            while (av_audio_fifo_size(fifo) >= frame_size) {\n                read_from_fifo(fifo, frame->data, frame_size);\n                frame->nb_samples = codec_ctx->frame_size;\n                frame->pts = pts;\n                ret = avcodec_send_frame(codec_ctx, frame);\n                if(ret < 0){\n                    qDebug() << \"向编码器发送数据包失败!\";\n                    return;\n                }\n                while(ret >= 0){\n                    ret = avcodec_receive_packet(codec_ctx, newpkt);\n                    if(ret < 0){\n                        if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\n                            break;\n                        }\n                        qDebug() << \"Error, encoding video frame\";\n                        return;\n                    }\n                    newpkt->pts = newpkt->dts = pts;\n                    newpkt->stream_index = audio_stream_index;\n                    //av_interleaved_write_frame(*ofmt_ctx, newpkt);\n                    CallbackFun write = std::bind(&MainWindow::Main_av_interleaved_write_frame, static_cast<MainWindow *>(parent), *ofmt_ctx, newpkt);\n                    write();\n                    av_packet_unref(newpkt);\n                }\n                pts += frame_size;\n            }\n            av_frame_unref(frame);\n        }\n        av_packet_unref(&pkt); // Free the packet data after each read\n    }\n```","tags":["FFmpeg","QT","AAC"],"categories":["音视频"]},{"title":"SQL基础","url":"/2024/11/28/SQL基础/","content":"\n# 数据库约束与高级操作总结\n\n## 约束\n\n### 概念\n约束是作用于表中字段上的规则，用于限制存储在表中的数据。\n\n**目的**: 保证数据库中数据的正确性、有效性和完整性。\n\n**分类**:\n- **非空约束**: 限制字段数据不能为 NULL  \n  ```sql\n  NOT NULL\n  ```\n\n- **唯一约束**: 保证字段数据唯一、不重复  \n  ```sql\n  UNIQUE\n  ```\n\n- **主键约束**: 主键是行数据的唯一标识，要求非空且唯一  \n  ```sql\n  PRIMARY KEY\n  ```\n\n- **默认约束**: 保存数据时未指定字段值，则采用默认值  \n  ```sql\n  DEFAULT\n  ```\n\n- **检查约束** (8.0.16版本之后): 保证字段值满足条件  \n  ```sql\n  CHECK\n  ```\n\n- **外键约束**: 用来建立表间数据的关联，保证一致性与完整性  \n  ```sql\n  FOREIGN KEY\n  ```\n\n---\n\n### 外键约束\n\n#### 概念\n外键用于在两张表之间建立数据连接，保证数据的一致性和完整性。\n\n#### 语法\n- **添加外键**\n  ```sql\n  CREATE TABLE 表名 (\n    字段名 数据类型,\n    ...\n    [CONSTRAINT 外键名称] FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名)\n  );\n\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名);\n  ```\n\n- **删除外键**\n  ```sql\n  ALTER TABLE 表名 DROP FOREIGN KEY 外键名称;\n  ```\n\n#### 删除/更新行为\n- `NO ACTION`: 检查外键关联，不允许删除/更新。\n- `RESTRICT`: 与 `NO ACTION` 类似，不允许删除/更新。\n- `CASCADE`: 删除/更新父表记录时，同时删除/更新子表记录。\n- `SET NULL`: 删除父表记录时，将子表外键字段设置为 `NULL`。\n- `SET DEFAULT`: 设置子表外键字段为默认值（InnoDB 不支持）。\n\n**示例**:\n```sql\nALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名 (主表字段名) ON UPDATE CASCADE ON DELETE CASCADE;\n```\n\n---\n\n## 多表查询\n\n### 概述\n多表查询指从多张表中获取数据。  \n需要避免无效的 **笛卡尔积**，即两张表中所有数据的组合。\n\n### 多表查询分类\n1. **连接查询**\n   - **内连接**: 获取两张表交集部分的数据。\n   - **左连接**: 获取左表所有数据及交集部分数据。\n   - **右连接**: 获取右表所有数据及交集部分数据。\n   - **自连接**: 表与自身的连接查询，必须使用表别名。\n\n2. **子查询**  \n   在 SQL 语句中嵌套 `SELECT` 语句，称为嵌套查询或子查询。\n\n#### 内连接\n- **隐式内连接**\n  ```sql\n  SELECT 字段列表 FROM 表1, 表2 WHERE 条件;\n  ```\n\n- **显示内连接**\n  ```sql\n  SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;\n  ```\n\n#### 自连接\n自连接是将一张表视为两张表，设置表别名进行查询。\n\n---\n\n## 事务\n\n### 概念\n事务是一组操作的集合，是一个不可分割的工作单位。  \n事务中的所有操作要么全部成功，要么全部失败。\n\n### 事务操作\n- **查看/设置事务提交方式**\n  ```sql\n  SELECT @@autocommit; -- 1 表示自动提交，0 表示手动提交\n\n  SET @@autocommit = 0;\n  ```\n\n- **开启事务**\n  ```sql\n  START TRANSACTION;\n  ```\n\n- **提交事务**\n  ```sql\n  COMMIT;\n  ```\n\n- **回滚事务**\n  ```sql\n  ROLLBACK;\n  ```\n\n### 事务并发问题\n1. **脏读**: 读取到未提交的数据。\n2. **不可重复读**: 一次事务中，数据多次读取结果不同。\n3. **幻读**: 一次事务中新增或删除数据导致总记录数不一致。\n\n### 事务隔离级别\n| 隔离级别           | 脏读 | 不可重复读 | 幻读 |\n|--------------------|-------|------------|-------|\n| Read uncommitted  | 会    | 会         | 会    |\n| Read committed    | 不会  | 会         | 会    |\n| Repeatable Read   | 不会  | 不会       | 会    |\n| Serializable      | 不会  | 不会       | 不会  |\n\n- **查看事务隔离级别**\n  ```sql\n  SELECT @@TRANSACTION_ISOLATION;\n  ```\n\n- **设置事务隔离级别**\n  ```sql\n  SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE};\n  ```","tags":["数据库","SQL"],"categories":["SQL"]},{"title":"四种SQL语句","url":"/2024/11/28/四种SQL语句/","content":"\n# 数据库操作与命令总结\n\n## DLL 定义\n\n### 数据库操作\n```sql\nSHOW DATABASES;\n\nCREATE DATABASE 数据库表名;\n\nUSE 数据库名;\n\nSELECT DATABASE(); -- 展示当前所在的数据库\n\nDROP DATABASE 数据库名; -- 删除数据库\n```\n\n### 表操作\n```sql\nSHOW TABLES;\n\nCREATE TABLE 表名 (字段 字段类型, ...);\n\nDESC 表名; -- 查看当前的表结构\n\nSHOW CREATE TABLE 表名;\n\nDROP TABLE 表名;\n```\n\n### 表操作 - 修改\n- **添加字段**\n  ```sql\n  ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释] [约束];\n  ```\n\n- **修改字段类型**\n  ```sql\n  ALTER TABLE 表名 MODIFY 字段名 数据类型(长度);\n  ```\n\n- **修改字段名和字段类型**\n  ```sql\n  ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释] [约束];\n  ```\n\n- **删除字段**\n  ```sql\n  ALTER TABLE 表名 DROP 字段名;\n  ```\n\n- **修改表名**\n  ```sql\n  ALTER TABLE 表名 RENAME TO 新表名;\n  ```\n\n- **删除表**\n  ```sql\n  DROP TABLE [IF EXISTS] 表名;\n  ```\n\n- **删除并重新创建表**\n  ```sql\n  TRUNCATE TABLE 表名;\n  ```\n\n---\n\n## DML 修改\n\n### 添加数据 (INSERT)\n```sql\n-- 给指定字段添加数据\nINSERT INTO 表名 (字段名1, 字段名2...) VALUES (值1, 值2, ...);\n\n-- 给全部字段添加数据\nINSERT INTO 表名 VALUES (值1, 值2, ...);\n\n-- 批量添加数据\nINSERT INTO 表名 (字段名1, 字段名...) VALUES (值1, 值2...), (值1, 值2...), ...;\n\nINSERT INTO 表名 VALUES (值1, 值2...), (值1, 值2...), ...;\n```\n\n### 修改数据 (UPDATE)\n```sql\nUPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ... [WHERE 条件];\n```\n\n### 删除数据 (DELETE)\n```sql\nDELETE FROM 表名 [WHERE 条件];\n-- 注意: 不能删除某个字段的值, 要用 UPDATE;\n```\n\n---\n\n## DQL 查询\n\n### 基本查询\n```sql\n-- 查询多个字段\nSELECT 字段1, 字段2, ... FROM 表名;\n\nSELECT * FROM 表名;\n\n-- 设置别名\nSELECT 字段1 [AS 别名1], 字段2 [AS 别名2], ... FROM 表名;\n\n-- 去除重复记录\nSELECT DISTINCT 字段列表 FROM 表名;\n```\n\n### 条件查询\n```sql\nSELECT 字段列表 FROM 表名 WHERE 条件列表;\n-- 常见条件:\n<> 或 !=      -- 不等于\nBETWEEN ... AND ... -- 在范围内 (含最大最小值)\nIN (...)      -- 在列表中\nLIKE 占位符    -- 模糊匹配 (_匹配单字符, %匹配任意字符)\nIS NULL       -- 是 NULL\n```\n\n### 聚合函数\n```sql\n-- 常见聚合函数:\nCOUNT -- 统计数量\nMAX   -- 最大值\nMIN   -- 最小值\nAVG   -- 平均值\nSUM   -- 求和\n\n-- 使用示例:\nSELECT 聚合函数(字段列表) FROM 表名;\n```\n\n### 分组查询\n```sql\nSELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];\n```\n\n### 排序查询\n```sql\nSELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1, 字段2 排序方式2;\n-- 排序方式:\n-- ASC : 升序 (默认值)\n-- DESC: 降序\n```\n\n### 分页查询\n```sql\nSELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数;\n```\n\n---\n\n## DCL 控制\n\n### 用户管理\n```sql\n-- 查询用户\nUSE mysql;\nSELECT * FROM user;\n\n-- 创建用户\nCREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';\n\n-- 修改用户密码\nALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码';\n\n-- 删除用户\nDROP USER '用户名'@'主机名';\n```\n\n### 权限控制\n- **常用权限**\n  ```text\n  ALL, ALL PRIVILEGES -- 所有权限\n  SELECT              -- 查询数据\n  INSERT              -- 插入数据\n  UPDATE              -- 修改数据\n  DELETE              -- 删除数据\n  ALTER               -- 修改表\n  DROP                -- 删除数据库/表/视图\n  CREATE              -- 创建数据库/表\n  ```\n\n- **查询权限**\n  ```sql\n  SHOW GRANTS FOR '用户名'@'主机名';\n  ```\n\n- **授予权限**\n  ```sql\n  GRANT 权限列表 ON 数据库.表名 TO '用户名'@'主机名';\n  ```\n\n- **撤销权限**\n  ```sql\n  REVOKE 权限列表 ON 数据库.表名 FROM '用户名'@'主机名';\n  ```\n  > 注意: 数据库.表名 可以使用通配符 `*.*` 表示所有数据库的所有表。","tags":["数据库","SQL"],"categories":["SQL"]},{"title":"FFmpeg 基本命令","url":"/2024/11/28/FFmpeg 基本命令/","content":"\n# FFmpeg 使用命令\n\n## 查询可用设备\n```bash\nffmpeg -list_devices true -f dshow -i dummy\n```\n\n---\n\n## 录制\n\n- **摄像头录制**\n  ```bash\n  ffmpeg -f dshow -r 30 -i video=\"USB2.0 HD UVC WebCam\" output.yuv\n  ```\n\n- **麦克风录制**\n  ```bash\n  ffmpeg -f dshow -i audio=\"麦克风阵列 (Realtek(R) Audio)\" output.pcm\n  ```\n\n---\n\n## 播放\n\n- **播放视频**\n  ```bash\n  ffplay -i output.yuv -video_size 1280x720 -framerate 30 -pixel_format yuvj422p\n  ```\n\n- **播放音频**\n  ```bash\n  ffplay -i output.pcm -ar 48000 -f s16le\n  ```\n\n---\n\n## 处理原始数据\n\n- **提取 YUV 视频数据**\n  ```bash\n  ffmpeg -i input.mp4 -an -c:v rawvideo -pixel_format yuv420p out.yuv\n  ```\n\n- **提取 PCM 音频数据**\n  ```bash\n  ffmpeg -i input.mp4 -vn -ar 48000 -channels 2 -f s16le output.pcm\n  ```\n\n---\n\n## 视频滤镜\n\n- **裁剪视频宽高各减 200**\n  ```bash\n  ffmpeg -i input.mp4 -vf crop=in_w-200:in_h-200 -c:v libx264 -c:a copy output.mp4\n  ```\n\n- **从指定时间开始裁剪 10 秒**\n  ```bash\n  ffmpeg -i input.mp4 -ss 00:00:00 -t 10 output.mp4\n  ```\n\n- **拼接多个视频**\n  ```bash\n  ffmpeg -f concat -i input.txt output.mp4\n  ```\n  > `input.txt` 文件内容示例：\n  > ```txt\n  > file 'file1.mp4'\n  > file 'file2.mp4'\n  > ```\n\n---\n\n## 图片与视频转换\n\n- **将视频转换为图片**\n  ```bash\n  ffmpeg -i input.mp4 -r 1 -f image2 image-%3d.jpeg\n  ```\n\n- **将图片转换为视频**\n  ```bash\n  ffmpeg -i image-%3d.jpeg out.mp4\n  ```\n\n# FFprobe 使用命令\n\n## 获取视频帧信息\n  ```bash\n  ffprobe -show_frames -select_streams v:0 -print_format json output.mp4\n  ```\n## 学习中...","tags":["FFmpeg"],"categories":["音视频"]}]